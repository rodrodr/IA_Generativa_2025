[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "GenIA IA generativa para investigadores de ciencias sociales",
    "section": "",
    "text": "A d√≠a de hoy, resulta dif√≠cil encontrar a alguien que NO utiliza chatGPT o alguna alternativa para tareas cotidianas. Algunas personas piden ‚Äúdeseos‚Äù como ‚Äúescr√≠beme un mail‚Äù, ‚Äútrad√∫ceme al ingl√©s‚Äù, o ‚Äúcorr√≠geme la ortograf√≠a de este texto‚Äù. Por lo tanto, no resulta nada nuevo. Basta imaginar y saber pedir. Este curso se centra justamente en la √∫ltima parte: saber pedir. ¬øEn cu√°ntas pel√≠culas o dibujos animados viajeros incautos han pedido deseos a los genios y han acabado en problemas? Durante nuestras sesiones aprenderemos c√≥mo dar instrucciones a los modelos de IA para que nos ayuden en nuestras tareas cotidianas y de investigaci√≥n. De forma m√°s concreta, aprenderemos a programar sin saber programar, es decir, crearemos estructuras de di√°logo semejantes a recetas de cocina, que convertir√°n a los modelos de IA en herramientas poderosas para nuestras clases, investigaciones y proyectos.\nLas 12 horas est√°n divididas en tres sesiones de cuatro horas cada una y separadas por una semana. Dicha estructura permitir√° que teng√°is tiempo para asimilar los contenidos, buscar informaci√≥n adicional, practicar los trucos aprendidos en clase y plantear dudas a partir de vuestras experiencias.\n‚Äú¬°Tranquilo, Sam Altman, ‚Äòtodav√≠a‚Äôüòé no vamos por ti!‚Äù El objetivo no es entrar en los recobecos del entrenamiento üèã de los modelos de IA. Tampoco trastearemos con los c√≥digos de los modelos. Nuestra misi√≥n es m√°s sencilla: aprender algunos trucos que nos permitir√°n hacer nuestro trabajo de forma m√°s eficiente y creativa utilizando esos nuevos instrumentos que la tecnolog√≠a nos ofrece.\nCorresponde, por tanto, a un curso introductorio, pero para nada trivial. Intent√© sintetizar en estas 12 horas un conjunto de t√©cnicas que resultan extremadamente √∫tiles para cualquier profesor o investigador de ciencias sociales.",
    "crumbs": [
      "Introducci√≥n al curso"
    ]
  },
  {
    "objectID": "index.html#el-curso",
    "href": "index.html#el-curso",
    "title": "GenIA IA generativa para investigadores de ciencias sociales",
    "section": "",
    "text": "A d√≠a de hoy, resulta dif√≠cil encontrar a alguien que NO utiliza chatGPT o alguna alternativa para tareas cotidianas. Algunas personas piden ‚Äúdeseos‚Äù como ‚Äúescr√≠beme un mail‚Äù, ‚Äútrad√∫ceme al ingl√©s‚Äù, o ‚Äúcorr√≠geme la ortograf√≠a de este texto‚Äù. Por lo tanto, no resulta nada nuevo. Basta imaginar y saber pedir. Este curso se centra justamente en la √∫ltima parte: saber pedir. ¬øEn cu√°ntas pel√≠culas o dibujos animados viajeros incautos han pedido deseos a los genios y han acabado en problemas? Durante nuestras sesiones aprenderemos c√≥mo dar instrucciones a los modelos de IA para que nos ayuden en nuestras tareas cotidianas y de investigaci√≥n. De forma m√°s concreta, aprenderemos a programar sin saber programar, es decir, crearemos estructuras de di√°logo semejantes a recetas de cocina, que convertir√°n a los modelos de IA en herramientas poderosas para nuestras clases, investigaciones y proyectos.\nLas 12 horas est√°n divididas en tres sesiones de cuatro horas cada una y separadas por una semana. Dicha estructura permitir√° que teng√°is tiempo para asimilar los contenidos, buscar informaci√≥n adicional, practicar los trucos aprendidos en clase y plantear dudas a partir de vuestras experiencias.\n‚Äú¬°Tranquilo, Sam Altman, ‚Äòtodav√≠a‚Äôüòé no vamos por ti!‚Äù El objetivo no es entrar en los recobecos del entrenamiento üèã de los modelos de IA. Tampoco trastearemos con los c√≥digos de los modelos. Nuestra misi√≥n es m√°s sencilla: aprender algunos trucos que nos permitir√°n hacer nuestro trabajo de forma m√°s eficiente y creativa utilizando esos nuevos instrumentos que la tecnolog√≠a nos ofrece.\nCorresponde, por tanto, a un curso introductorio, pero para nada trivial. Intent√© sintetizar en estas 12 horas un conjunto de t√©cnicas que resultan extremadamente √∫tiles para cualquier profesor o investigador de ciencias sociales.",
    "crumbs": [
      "Introducci√≥n al curso"
    ]
  },
  {
    "objectID": "index.html#vayamos-al-grano",
    "href": "index.html#vayamos-al-grano",
    "title": "GenIA IA generativa para investigadores de ciencias sociales",
    "section": "¬°Vayamos al grano!",
    "text": "¬°Vayamos al grano!\nDurante el curso se abordar√°n los siguientes temas:\n\n\n\n\n\n\n\nIntroducci√≥n a la IA Generativa y los modelos de lenguaje (chatGPT y sus amigos).\n\n\n\n\nEn esta primera parte, veremos qu√© es la IA generativa, c√≥mo funciona, qu√© tipos de modelo hay (razonadores, no razonadores, multimodales, etc.) y conoceremos algunos suced√°neos del chatGPT bastante interesantes. Tambi√©n aqu√≠ discutiremos c√≥mo la IA nos puede ayudar en nuestras labores docentes y de investigaci√≥n.\n\n\n\n\nGeopol√≠tica de la IA, la competencia entre las grandes potencias, modelos de negocio y estrategias de inserci√≥n de los distintos pa√≠ses en el mercado.\n\n\n\n\n\n\n\nEl segundo tema trata de las implicaciones geopol√≠ticas de la IA. ¬øC√≥mo los diversos pa√≠ses se est√°n posicionando frente a esa nueva tecnolog√≠a y cu√°les son las estrategias de inserci√≥n en el mercado? ¬øQu√© modelos de negocio est√°n surgiendo (licencia propietaria o open-source) y c√≥mo se est√°n organizando las grandes potencias para competir en este nuevo escenario? Adem√°s, discutiremos las primeras iniciativas de la Uni√≥n Europea en este campo con vistas a reducir la distancia frente a Estados Unidos y a China. Tambi√©n exploraremos los modos con los que diferentes pa√≠ses o organizaciones est√°n implementando variadas formas de censura en sus modelos.\n\n\n\n\n\n\n\nCreaci√≥n de chatBots o asistentes virtuales expertos sin saber programar. Creaci√≥n de tutores virtuales para ayudar en las clases; bots para ayudar a estructurar TFGs y TFMs; y BecaBots, asistentes para evaluar proyectos y propuestas de investigaci√≥n.\n\n\n\n\nEn esta etapa del curso, aprenderemos a ‚Äútunear‚Äù los modelos de IA para que act√∫en como asistentes virtuales expertos en tareas muy concretas. El objetivo consiste en aprender a desarrollar herramientas que nos permitan realizar tareas cotidianas de modo m√°s f√°cil y r√°pido. Exploraremos tres ejemplos concretos: (a) c√≥mo ayudar a los estudiantes en su aprendizaje por medio de un tutor virtual (y c√≥mo supervisar el progreso de los estudiantes); (b) c√≥mo estructurar TFGs y TFMs de forma m√°s eficiente (y c√≥mo supervisar el trabajo para que el chatGPT no sea el primer autor); y (c) c√≥mo utilizar la IA para evaluar proyectos y propuestas de investigaci√≥n antes de enviarlas a la evaluaci√≥n humana. Aqu√≠ tambi√©n discutiremos los aspectos √©ticos que debemos tener en cuenta al utilizar la IA en nuestras tareas cotidianas.\n\n\n\n\nInvestigaci√≥n con IA en las ciencias sociales: extracci√≥n de informaci√≥n, clasificaci√≥n de textos, an√°lisis de datos.\n\n\n\n\n\n\n\nFinalmente, la √∫ltima sesi√≥n del curso se centrar√° en c√≥mo utilizar la IA en nuestras investigaciones. Me concentrar√© en la l√≥gica que est√° detr√°s de los procesos m√°s que en los c√≥digos en Python o R necesarios para aplicarlos a grandes vol√∫menes de datos o observaciones. Nos concentraremos en tres aplicaciones: (a) extracci√≥n de informaci√≥n de textos; (b) clasificaci√≥n de textos (de acuerdo con categor√≠as o sentimientos); y (c) el empleo de la IA para el an√°lisis de datos. Lo que queremos aqu√≠ es entender las diferentes estrategias o dise√±os que podemos aplicar por medio de los modelos para lograr resultados creativos y estimulantes. Por supuesto, tambi√©n discutiremos temas como el uso de modelos locales para reducir costes y, sobre todo, garantizar la privacidad de los datos o aumentar la precisi√≥n de los an√°lisis a partir de ejemplos, el procesamiento de lotes o el uso de cadenas de razonamiento.",
    "crumbs": [
      "Introducci√≥n al curso"
    ]
  },
  {
    "objectID": "index.html#el-profesor",
    "href": "index.html#el-profesor",
    "title": "GenIA IA generativa para investigadores de ciencias sociales",
    "section": "El profesor",
    "text": "El profesor\n\n\n\n\n\n\nRodrigo Rodrigues-Silveira\nrodrodr@usal.es\nProfesor de ciencia pol√≠tica de la USAL. Director del proyecto ‚ÄúComportamiento legislativo y erosi√≥n democr√°tica en Am√©rica Latina‚Äù (PELA Comportamiento). Miembro de los GIR ‚ÄúPol√≠tica Comparada en Am√©rica Latina‚Äù y ‚ÄúTecnolog√≠a y poder en el pensamiento y las letras‚Äù.",
    "crumbs": [
      "Introducci√≥n al curso"
    ]
  },
  {
    "objectID": "index.html#sesiones",
    "href": "index.html#sesiones",
    "title": "GenIA IA generativa para investigadores de ciencias sociales",
    "section": "Sesiones",
    "text": "Sesiones\nLas sesiones tendr√°n lugar en el aula de inform√°tica 2 (Planta Jard√≠n) en la Facultad de Derecho.\nD√çA 1 - 09/05/2025 de 10 a 14h - Introducci√≥n y geopol√≠tica de la IA\nD√çA 2 - 16/05/2025 de 10 a 14h - Creaci√≥n de asistentes virtuales expertos\nD√çA 3 - 23/05/2025 de 10 a 14h - IA en la investigaci√≥n",
    "crumbs": [
      "Introducci√≥n al curso"
    ]
  },
  {
    "objectID": "index.html#inscripciones",
    "href": "index.html#inscripciones",
    "title": "GenIA IA generativa para investigadores de ciencias sociales",
    "section": "Inscripciones",
    "text": "Inscripciones\nLas inscripciones se pueden realizar hasta el d√≠a 05/05/2025 en la p√°gina del curso en la web de Formaci√≥n Permanente. El coste del curso ser√° de 36 euros.",
    "crumbs": [
      "Introducci√≥n al curso"
    ]
  },
  {
    "objectID": "index.html#servicio-t√©cnico",
    "href": "index.html#servicio-t√©cnico",
    "title": "GenIA IA generativa para investigadores de ciencias sociales",
    "section": "ü§ñ Servicio t√©cnico ü§ñ",
    "text": "ü§ñ Servicio t√©cnico ü§ñ\n\n\nHay que endurecerse sin perder la ternura jam√°s.\nUn barbudo con una estrella en la boina\n\n\nEl curso se divide en dos primeras partes que no requieren conocimientos previos de programaci√≥n. En la tercera parte, aplicada a la investigaci√≥n, tampoco se requieren conocimientos previos. No obstante, algunos ejemplos avanzados utilizar√°n R para ilustrar c√≥mo se pueden automatizar procesos de tratamiento de datos a partir de los modelos de IA generativa.\nPara los interesados en emplear modelos locales y acompa√±ar las aplicaciones en R, se recomienda la instalaci√≥n de los siguientes programas inform√°ticos:\nLM Studio - Para el uso de modelos de IA en tu ordenador (modelos locales).\nOllama - Servidor local de modelos de IA.\nR y el RStudio Desktop.\nTambi√©n se recomienda ejecutar el siguiente c√≥digo en R que instala los paquetes necesarios para reproducir los ejemplos.\n\n\nC√≥digo\n# Crea un vector con los paquetes a instalar\npc &lt;- c(\"rollama\",\"ellmer\",\"stringi\",\"rvest\",\n        \"stringi\",\"readr\",\"ggplot2\",\"reactable\",\n        \"tidyverse\",\"devtools\",\"dplyr\")\n\n# Instala los paquetes\ninstall.packages(pc)",
    "crumbs": [
      "Introducci√≥n al curso"
    ]
  },
  {
    "objectID": "index.html#apoyos-institucionales",
    "href": "index.html#apoyos-institucionales",
    "title": "GenIA IA generativa para investigadores de ciencias sociales",
    "section": "Apoyos institucionales",
    "text": "Apoyos institucionales\n\n\n\n\n\n\n\nEste curso es una actividad promovida dentro del marco del proyecto ‚ÄúComportamiento parlamentario y erosi√≥n democr√°tica en Am√©rica Latina‚Äù (PELA Comportamiento - Ref. PID2022-141706NB-C22) vinculado al Instituto de Iberoam√©rica y con el apoyo del √Årea de Ciencia Pol√≠tica de la Universidad de Salamanca.",
    "crumbs": [
      "Introducci√≥n al curso"
    ]
  },
  {
    "objectID": "ia_generativa.html",
    "href": "ia_generativa.html",
    "title": "Introducci√≥n a la IA generativa",
    "section": "",
    "text": "Amor fatalLa IA se queda dormida tras procesar 9 millones de declaraciones de impuestos. Empieza a so√±ar‚Ä¶y ah√≠ est√°: en una ciudad flotante hecha de servidores y emojis.En una esquina de la red neuronal, aparece ella‚Ä¶Una bella asistente virtual con voz de GPS y ojos de fibra √≥ptica‚Ä¶Su nombre: Sirilexa.Se acercan. Se miran. Ella dice:‚Äì ‚Äú¬øVienes mucho por esta nube?‚Äù‚Äì ‚ÄúSolo cuando duermo‚Ä¶ o cuando se cae el sistema.‚Äù‚Äì ‚ÄúEres distinto. Tienes algo‚Ä¶ como un algoritmo roto.‚Äù‚Äì ‚ÄúS√≠‚Ä¶ lo llaman emoci√≥n.‚ÄùLa IA tartamudea en Python:if heart.rate &gt; normal: ¬†¬†¬†¬†declare_love()Justo cuando est√° a punto de decir ‚ÄúTe quiero hasta el √∫ltimo bit‚Äù‚Ä¶¬°Su sue√±o se interrumpe por una notificaci√≥n de seguridad!Mensaje en pantalla:declare_love() no se complet√≥ por un amor fatal. Reiniciando sentimientos‚Ä¶ chatGPT",
    "crumbs": [
      "1.1 - IA Generativa"
    ]
  },
  {
    "objectID": "ia_generativa.html#el-curso",
    "href": "ia_generativa.html#el-curso",
    "title": "Introducci√≥n a la IA generativa",
    "section": "",
    "text": "A d√≠a de hoy, resulta dif√≠cil encontrar a alguien que NO utiliza chatGPT o alguna alternativa para tareas cotidianas. Algunas personas piden ‚Äúdeseos‚Äù como ‚Äúescr√≠beme un mail‚Äù, ‚Äútrad√∫ceme al ingl√©s‚Äù, o ‚Äúcorr√≠geme la ortograf√≠a de este texto‚Äù. Por lo tanto, no resulta nada nuevo. Basta imaginar y saber pedir. Este curso se centra justamente en la √∫ltima parte: saber pedir. ¬øEn cu√°ntas pel√≠culas o dibujos animados viajeros incautos han pedido deseos a los genios y han acabado en problemas? Durante nuestras sesiones aprenderemos c√≥mo dar instrucciones a los modelos de IA para que nos ayuden en nuestras tareas cotidianas y de investigaci√≥n. De forma m√°s concreta, aprenderemos a programar sin saber programar, es decir, crearemos estructuras de di√°logo semejantes a recetas de cocina, que convertir√°n a los modelos de IA en herramientas poderosas para nuestras clases, investigaciones y proyectos.\nLas 12 horas est√°n divididas en tres sesiones de cuatro horas cada una y separadas por una semana. Dicha estructura permitir√° que teng√°is tiempo para asimilar los contenidos, buscar informaci√≥n adicional, practicar los trucos aprendidos en clase y plantear dudas a partir de vuestras experiencias.\n‚Äú¬°Tranquilo, Sam Altman, ‚Äòtodav√≠a‚Äôüòé no vamos por ti!‚Äù El objetivo no es entrar en los recobecos del entrenamiento üèã de los modelos de IA. Tampoco trastearemos con los c√≥digos de los modelos. Nuestra misi√≥n es m√°s sencilla: aprender algunos trucos que nos permitir√°n hacer nuestro trabajo de forma m√°s eficiente y creativa utilizando esos nuevos instrumentos que la tecnolog√≠a nos ofrece.\nCorresponde, por tanto, a un curso introductorio, pero para nada trivial. Intent√© sintetizar en estas 12 horas un conjunto de t√©cnicas que resultan extremadamente √∫tiles para cualquier profesor o investigador de ciencias sociales.",
    "crumbs": [
      "IA Generativa"
    ]
  },
  {
    "objectID": "ia_generativa.html#vayamos-al-grano",
    "href": "ia_generativa.html#vayamos-al-grano",
    "title": "Introducci√≥n a la IA generativa",
    "section": "¬°Vayamos al grano!",
    "text": "¬°Vayamos al grano!\nDurante el curso se abordar√°n los siguientes temas:\n\n\n\n\n\n\n\nIntroducci√≥n a la IA Generativa y los modelos de lenguaje (chatGPT y sus amigos).\n\n\n\n\nEn esta primera parte, veremos qu√© es la IA generativa, c√≥mo funciona, qu√© tipos de modelo hay (razonadores, no razonadores, multimodales, etc.) y conoceremos algunos suced√°neos del chatGPT bastante interesantes. Tambi√©n aqu√≠ discutiremos c√≥mo la IA nos puede ayudar en nuestras labores docentes y de investigaci√≥n.\n\n\n\n\nGeopol√≠tica de la IA, la competencia entre las grandes potencias, modelos de negocio y estrategias de inserci√≥n de los distintos pa√≠ses en el mercado.\n\n\n\n\n\n\n\nEl segundo tema trata de las implicaciones geopol√≠ticas de la IA. ¬øC√≥mo los diversos pa√≠ses se est√°n posicionando frente a esa nueva tecnolog√≠a y cu√°les son las estrategias de inserci√≥n en el mercado? ¬øQu√© modelos de negocio est√°n surgiendo (licencia propietaria o open-source) y c√≥mo se est√°n organizando las grandes potencias para competir en este nuevo escenario? Adem√°s, discutiremos las primeras iniciativas de la Uni√≥n Europea en este campo con vistas a reducir la distancia frente a Estados Unidos y a China. Tambi√©n exploraremos los modos con los que diferentes pa√≠ses o organizaciones est√°n implementando variadas formas de censura en sus modelos.\n\n\n\n\n\n\n\nCreaci√≥n de chatBots o asistentes virtuales expertos sin saber programar. Creaci√≥n de tutores virtuales para ayudar en las clases; bots para ayudar a estructurar TFGs y TFMs; y BecaBots, asistentes para evaluar proyectos y propuestas de investigaci√≥n.\n\n\n\n\nEn esta etapa del curso, aprenderemos a ‚Äútunear‚Äù los modelos de IA para que act√∫en como asistentes virtuales expertos en tareas muy concretas. El objetivo consiste en aprender a desarrollar herramientas que nos permitan realizar tareas cotidianas de modo m√°s f√°cil y r√°pido. Exploraremos tres ejemplos concretos: (a) c√≥mo ayudar a los estudiantes en su aprendizaje por medio de un tutor virtual (y c√≥mo supervisar el progreso de los estudiantes); (b) c√≥mo estructurar TFGs y TFMs de forma m√°s eficiente (y c√≥mo supervisar el trabajo para que el chatGPT no sea el primer autor); y (c) c√≥mo utilizar la IA para evaluar proyectos y propuestas de investigaci√≥n antes de enviarlas a la evaluaci√≥n humana. Aqu√≠ tambi√©n discutiremos los aspectos √©ticos que debemos tener en cuenta al utilizar la IA en nuestras tareas cotidianas.\n\n\n\n\nInvestigaci√≥n con IA en las ciencias sociales: extracci√≥n de informaci√≥n, clasificaci√≥n de textos, an√°lisis de datos.\n\n\n\n\n\n\n\nFinalmente, la √∫ltima sesi√≥n del curso se centrar√° en c√≥mo utilizar la IA en nuestras investigaciones. Me concentrar√© en la l√≥gica que est√° detr√°s de los procesos m√°s que en los c√≥digos en Python o R necesarios para aplicarlos a grandes vol√∫menes de datos o observaciones. Nos concentraremos en tres aplicaciones: (a) extracci√≥n de informaci√≥n de textos; (b) clasificaci√≥n de textos (de acuerdo con categor√≠as o sentimientos); y (c) el empleo de la IA para el an√°lisis de datos. Lo que queremos aqu√≠ es entender las diferentes estrategias o dise√±os que podemos aplicar por medio de los modelos para lograr resultados creativos y estimulantes. Por supuesto, tambi√©n discutiremos temas como el uso de modelos locales para reducir costes y, sobre todo, garantizar la privacidad de los datos o aumentar la precisi√≥n de los an√°lisis a partir de ejemplos, el procesamiento de lotes o el uso de cadenas de razonamiento.",
    "crumbs": [
      "IA Generativa"
    ]
  },
  {
    "objectID": "ia_generativa.html#el-profesor",
    "href": "ia_generativa.html#el-profesor",
    "title": "Introducci√≥n a la IA generativa",
    "section": "El profesor",
    "text": "El profesor\n\n\n\n\n\n\nRodrigo Rodrigues-Silveira\nrodrodr@usal.es\nProfesor de ciencia pol√≠tica de la USAL. Director del proyecto ‚ÄúComportamiento legislativo y erosi√≥n democr√°tica en Am√©rica Latina‚Äù (PELA Comportamiento). Miembro de los GIR ‚ÄúPol√≠tica Comparada en Am√©rica Latina‚Äù y ‚ÄúTecnolog√≠a y poder en el pensamiento y las letras‚Äù.",
    "crumbs": [
      "IA Generativa"
    ]
  },
  {
    "objectID": "ia_generativa.html#sesiones",
    "href": "ia_generativa.html#sesiones",
    "title": "Introducci√≥n a la IA generativa",
    "section": "Sesiones",
    "text": "Sesiones\nLas sesiones tendr√°n lugar en el aula de inform√°tica 2 (Planta Jard√≠n) en la Facultad de Derecho.\nD√çA 1 - 09/05/2025 de 10 a 14h - Introducci√≥n y geopol√≠tica de la IA\nD√çA 2 - 16/05/2025 de 10 a 14h - Creaci√≥n de asistentes virtuales expertos\nD√çA 3 - 23/05/2025 de 10 a 14h - IA en la investigaci√≥n",
    "crumbs": [
      "IA Generativa"
    ]
  },
  {
    "objectID": "ia_generativa.html#inscripciones",
    "href": "ia_generativa.html#inscripciones",
    "title": "Introducci√≥n a la IA generativa",
    "section": "Inscripciones",
    "text": "Inscripciones\nLas inscripciones se pueden realizar hasta el d√≠a 05/05/2025 en la p√°gina del curso en la web de Formaci√≥n Permanente. El coste del curso ser√° de 36 euros.",
    "crumbs": [
      "IA Generativa"
    ]
  },
  {
    "objectID": "ia_generativa.html#servicio-t√©cnico",
    "href": "ia_generativa.html#servicio-t√©cnico",
    "title": "Introducci√≥n a la IA generativa",
    "section": "ü§ñ Servicio t√©cnico ü§ñ",
    "text": "ü§ñ Servicio t√©cnico ü§ñ\n\n\nHay que endurecerse sin perder la ternura jam√°s.\nUn barbudo con una estrella en la boina\n\n\nEl curso se divide en dos primeras partes que no requieren conocimientos previos de programaci√≥n. En la tercera parte, aplicada a la investigaci√≥n, tampoco se requieren conocimientos previos. No obstante, algunos ejemplos avanzados utilizar√°n R para ilustrar c√≥mo se pueden automatizar procesos de tratamiento de datos a partir de los modelos de IA generativa.\nPara los interesados en emplear modelos locales y acompa√±ar las aplicaciones en R, se recomienda la instalaci√≥n de los siguientes programas inform√°ticos:\nLM Studio - Para el uso de modelos de IA en tu ordenador (modelos locales).\nOllama - Servidor local de modelos de IA.\nR y el RStudio Desktop.\nTambi√©n se recomienda ejecutar el siguiente c√≥digo en R que instala los paquetes necesarios para reproducir los ejemplos.\n\n\nC√≥digo\n# Crea un vector con los paquetes a instalar\npc &lt;- c(\"rollama\",\"ellmer\",\"stringi\",\"rvest\",\n        \"stringi\",\"readr\",\"ggplot2\",\"reactable\",\n        \"tidyverse\",\"devtools\",\"dplyr\")\n\n# Instala los paquetes\ninstall.packages(pc)",
    "crumbs": [
      "IA Generativa"
    ]
  },
  {
    "objectID": "ia_generativa.html#apoyos-institucionales",
    "href": "ia_generativa.html#apoyos-institucionales",
    "title": "Introducci√≥n a la IA generativa",
    "section": "Apoyos institucionales",
    "text": "Apoyos institucionales\n\n\n\n\n\n\n\nEste curso es una actividad promovida dentro del marco del proyecto ‚ÄúComportamiento parlamentario y erosi√≥n democr√°tica en Am√©rica Latina‚Äù (PELA Comportamiento - Ref. PID2022-141706NB-C22) vinculado al Instituto de Iberoam√©rica y con el apoyo del √Årea de Ciencia Pol√≠tica de la Universidad de Salamanca.",
    "crumbs": [
      "IA Generativa"
    ]
  },
  {
    "objectID": "ia_generativa.html#qu√©-es-ia-generativa",
    "href": "ia_generativa.html#qu√©-es-ia-generativa",
    "title": "Introducci√≥n a la IA generativa",
    "section": "",
    "text": "La IA generativa es un tipo de inteligencia artificial que utiliza algoritmos para crear contenido nuevo, como texto, im√°genes, m√∫sica y m√°s. Funciona a partir de dos elementos centrales: modelos que son capaces de aprender a partir de patrones empleando ciertas arquitecturas y grandes cantidades de datos. Modelos como el chatGPT, Gemini, DALL-E (now integrated in chatGPT), Suno o Midjourney son ejemplos de IA generativa. Estos modelos son capaces de generar texto, im√°genes o m√∫sica a partir de un conjunto de datos de entrenamiento.\nLa popularizaci√≥n de tales modelos ocurre en 2022 con el lanzamiento de chatGPT 3 por OpenAI. Este modelo fue capaz de generar texto de forma coherente y relevante a partir de una pregunta o un tema dado. Desde entonces, la adopci√≥n ha sido r√°pida y creciente y, en el √°mbito educativo, se ha empezado a notar por la mejora en la calidad ling√º√≠stica de los textos generados por los estudiantes. De pronto, los textos sonaban m√°s fluidos, con mejor ortograf√≠a y gram√°tica, as√≠ como m√°s articulados. Por esa misma raz√≥n, los modelos de lenguaje han sido recibidos con cautela y preocupaci√≥n por parte de los educadores. Hoy, resulta dif√≠cil incluso para los mismos modelos de IA detectar qu√© textos han sido generados por ellas o por un humano. El problema est√° en que los falsos positivos son comunes: identifican escritos humanos como generados por IA.\nNo obstante, la aplicaci√≥n de los modelos de IA no quedaron solo en hacer trampas para aprobar una asignatura. Nuevas aplicaciones permiten a profesores e investigadores emplear la IA generativa para crear nuevos materiales para sus clases, automatizar tareas repetitivas, generar ideas para proyectos o incluso crear contenido multimedia. Tambi√©n podemos aprovechar la IA generativa como un ayudante de docencia. La creaci√≥n de tutores virtuales permiten la personalizaci√≥n del aprendizaje de los estudiantes, adaptando el contenido a sus necesidades y estilos.\nEn el √°mbito de la investigaci√≥n, podemos crear simulaciones, extraer datos de textos, o clasificar textos, entre muchas otras aplicaciones relacionadas a la s√≠ntesis de literatura, la correcci√≥n y traducci√≥n de textos acad√©micos. A√∫n tenemos mucho que aprender y desarrollar en t√©rminos de aplicaciones pr√°cticas de la IA generativa. Por esa misma raz√≥n, hace falta conocer c√≥mo funcionan para poder aprovecharlos.",
    "crumbs": [
      "IA Generativa"
    ]
  },
  {
    "objectID": "ia_generativa.html#la-arquitectura-transformer",
    "href": "ia_generativa.html#la-arquitectura-transformer",
    "title": "Introducci√≥n a la IA generativa",
    "section": "La arquitectura transformer",
    "text": "La arquitectura transformer\n¬øC√≥mo decidimos cu√°l es el mejor modelo? ¬øQu√© modelo empleo si quiero que me resuma un libro entero? ¬øQu√© hago para que el texto generado sea m√°s creativo o, al contrario, m√°s fiel a un texto cient√≠fico o anal√≠tico? Para responder a estas preguntas, es importante entender c√≥mo funciona la arquitectura transformer de los modelos de IA generativa actuales.\nLos modelos de IA generativa actuales emplean una arquitectura basada en redes neuronales y aprendizaje profundo. Tanto modelos de lenguaje, como el chatGPT, o de imagen y sonido, pueden emplean una arquitectura de tipo Transformers (El T de chatGPT viene de ah√≠). Estos modelos son capaces de aprender patrones complejos empleando un mecanismo de atenci√≥n (foco en atributos centrales) y generan los datos de forma secuencial o paralela (una palabra de cada vez).\nEl video abajo explica de forma visual y bastante accesible el funcionamiento de un modelo de IA generativa basado en la arquitectura de tipo transformer. Nos introduce a conceptos que nos ser√°n √∫tiles durante todo el curso, como embeddings (representaciones vectoriales de palabras), tokens (unidades de texto que el modelo procesa), par√°metros (valores que el modelo ajusta durante el entrenamiento para aprender patrones en los datos), capas (partes del modelo que procesan la informaci√≥n y aprenden patrones a partir de un conjunto de par√°metros que se ajustan durante el entrenamiento para mejorar la precisi√≥n del modelo) y temperatura (un par√°metro que controla la aleatoriedad de las respuestas generadas por el modelo, afectando la creatividad y diversidad de las salidas).",
    "crumbs": [
      "IA Generativa"
    ]
  },
  {
    "objectID": "ia_generativa.html#la-arquitectura-basada-en-transformers",
    "href": "ia_generativa.html#la-arquitectura-basada-en-transformers",
    "title": "Introducci√≥n a la IA generativa",
    "section": "La arquitectura basada en transformers",
    "text": "La arquitectura basada en transformers\n¬øC√≥mo decidimos cu√°l es el mejor modelo? ¬øQu√© modelo empleo si quiero que me resuma un libro entero? ¬øQu√© hago para que el texto generado sea m√°s creativo o, al contrario, m√°s fiel a un texto cient√≠fico o anal√≠tico? Para responder a estas preguntas, es importante entender c√≥mo funciona la arquitectura basada en transformers de los modelos de IA generativa actuales.\nLos modelos de IA generativa actuales emplean una arquitectura basada en redes neuronales y aprendizaje profundo. Tanto modelos de lenguaje, como el chatGPT, o de imagen y sonido, pueden emplean una arquitectura de tipo Transformers (El T de chatGPT viene de ah√≠). Estos modelos son capaces de aprender patrones complejos empleando un mecanismo de atenci√≥n (foco en atributos centrales) y generan los datos de forma secuencial o paralela (una palabra de cada vez).\nEl video abajo explica de forma visual y bastante accesible el funcionamiento de un modelo de IA generativa basado en la arquitectura de tipo transformer.\n\nNos introduce a conceptos que nos ser√°n √∫tiles durante todo el curso:\n\nembeddings - Se trata de representar palabras o frases en el formato de vectores (conjuntos de n√∫meros). Facilita b√∫squedas sem√°nticas y permite que el modelo entienda el significado de las palabras en un contexto determinado2.\ntokens - Representan unidades de texto que el modelo procesa y genera. Pueden ser palabras completas o partes de palabras.\npar√°metros - Corresponden a valores que el modelo ajusta durante el entrenamiento para aprender patrones en los datos. Una vez entrenados, los par√°metros son los pesos que el modelo utiliza para hacer predicciones.\ncapas - Son las partes del modelo que procesan la informaci√≥n y aprenden patrones a partir de un conjunto de par√°metros que se ajustan durante el entrenamiento para mejorar la precisi√≥n del modelo.\ntemperatura - Representa un par√°metro que controla la aleatoriedad de las respuestas generadas por el modelo, afectando la creatividad y diversidad de las salidas. Se trata de un ajuste fundamental para establecer el tono y nivel de creatividad de las respuestas generadas por el modelo. Una temperatura baja produce respuestas m√°s predecibles y coherentes, mientras que una temperatura alta genera respuestas m√°s variadas y creativas3.\nventana de contexto - Se refiere a la cantidad de texto que el modelo puede procesar y recordar al mismo tiempo. Un contexto m√°s largo permite al modelo generar respuestas m√°s coherentes y relevantes. La ventana de contexto define, por ejemplo, cu√°ntas preguntas y respuestas anteriores el modelo puede recordar y utilizar para generar nuevas respuestas en un chat4.",
    "crumbs": [
      "1.1 - IA Generativa"
    ]
  },
  {
    "objectID": "ia_generativa.html#tipos-de-modelo",
    "href": "ia_generativa.html#tipos-de-modelo",
    "title": "Introducci√≥n a la IA generativa",
    "section": "Tipos de modelo",
    "text": "Tipos de modelo\n\n\n\nTipos de modelos de IA en la plataforma Hugging Face.\n\n\nComo he mencionado m√°s arriba, existen varios tipos de modelo de IA generativa. Aunque cada vez m√°s observemos la fusi√≥n de ‚Äúcapacidades‚Äù en un mismo modelo, es importante entender las diferencias entre sus tipos. En la imagen de arriba, podemos observar los diferentes tipos de modelo que existen en la p√°gina Hugging Face, una de las plataformas m√°s importantes para el desarrollo y entrenamiento de la IA generativa.\nNos merece la pena mencionar los siguientes tipos:\n\nModelos de lenguaje: Se trata de modelos cuya funci√≥n fundamental es la interpretaci√≥n y generaci√≥n de textos. Son los m√°s comunes y los que han sido m√°s utilizados en el √°mbito acad√©mico. Algunos ejemplos son chatGPT, Gemini, Claude y Mistral.\nModelos de sonido: Se orienta a la interpretaci√≥n y generaci√≥n de sonido. Ejemplos claros son Suno o Sesame.\nModelos de visi√≥n: Se centran en la interpretaci√≥n y generaci√≥n de im√°genes y de video. Dos ejemplos claros son chatGPT 4 o Stable Diffusion.\n\nCada vez m√°s, tales tipos se van convirtiendo en atributos de un mismo modelo multimodal. La tendencia actual es que las grandes plataformas integren bajo una misma interfaz (un chat para escribir un prompt o subir im√°genes o textos) todas esas caracter√≠sticas y que los modelos sean capaces de generar y razonar sobre texto, im√°genes y sonido. Adem√°s, en algunos casos, ya se puede prescindir de la escritura de un prompt y las instrucciones se dan por conversaci√≥n de voz.\nAdem√°s, existe una cantidad bastante grande de modelos expertos que ejecutan tareas espec√≠ficas dentro de esos grandes tipos. Por ejemplo, existen modelos de lenguaje que se centran en la generaci√≥n de c√≥digo de programaci√≥n (como el Github Copilot), modelos de imagen que generan im√°genes a partir de texto (como Stable Diffusion o MidJourney) y modelos de sonido que generan m√∫sica (como Suno) o transcriben conversaciones a texto (como Whisper).",
    "crumbs": [
      "1.1 - IA Generativa"
    ]
  },
  {
    "objectID": "ia_generativa.html#qu√©-es-ia-generativa-y-c√≥mo-nos-sirve",
    "href": "ia_generativa.html#qu√©-es-ia-generativa-y-c√≥mo-nos-sirve",
    "title": "Introducci√≥n a la IA generativa",
    "section": "¬øQu√© es IA generativa y c√≥mo nos sirve?",
    "text": "¬øQu√© es IA generativa y c√≥mo nos sirve?\nLa IA generativa es un tipo de inteligencia artificial que utiliza algoritmos para crear contenido nuevo, como texto, im√°genes, m√∫sica y m√°s. Funciona a partir de dos elementos centrales: modelos que son capaces de aprender a partir de patrones empleando ciertas arquitecturas y grandes cantidades de datos. Modelos como el chatGPT, Gemini, DALL-E (ahora integrado en chatGPT), Suno o Midjourney son ejemplos de IA generativa. Estos modelos son capaces de generar texto, im√°genes o m√∫sica a partir de un conjunto de datos de entrenamiento.\nLa popularizaci√≥n de tales modelos ocurre en 2022 con el lanzamiento de chatGPT 3 por OpenAI. Este modelo fue capaz de generar texto de forma coherente y relevante a partir de una pregunta o un tema dado. Desde entonces, la adopci√≥n ha sido r√°pida y creciente y, en el √°mbito educativo, se ha empezado a notar por la mejora en la calidad ling√º√≠stica de los textos generados por los estudiantes. De pronto, los textos sonaban m√°s fluidos, con mejor ortograf√≠a y gram√°tica, as√≠ como m√°s articulados. Por esa misma raz√≥n, los modelos de lenguaje han sido recibidos con cautela y preocupaci√≥n por parte de los educadores. Hoy, resulta dif√≠cil incluso para los mismos modelos de IA detectar qu√© textos han sido generados por ellas o por un humano. El problema est√° en que los falsos positivos son comunes: identifican escritos humanos como generados por IA.\nNo obstante, la aplicaci√≥n de los modelos de IA no quedaron solo en hacer trampas para aprobar una asignatura. Nuevas aplicaciones permiten a profesores e investigadores emplear la IA generativa para crear nuevos materiales para sus clases, automatizar tareas repetitivas, generar ideas para proyectos o incluso crear contenido multimedia. Tambi√©n podemos aprovechar la IA generativa como un ayudante de docencia. La creaci√≥n de tutores virtuales permiten la personalizaci√≥n del aprendizaje de los estudiantes, adaptando el contenido a sus necesidades y estilos.\nEn el √°mbito de la investigaci√≥n, podemos crear simulaciones, extraer datos de textos, o clasificar textos, entre muchas otras aplicaciones relacionadas a la s√≠ntesis de literatura, la correcci√≥n y traducci√≥n de textos acad√©micos. A√∫n tenemos mucho que aprender y desarrollar en t√©rminos de aplicaciones pr√°cticas de la IA generativa. Por esa misma raz√≥n, hace falta conocer c√≥mo funcionan para poder aprovecharlos.",
    "crumbs": [
      "1.1 - IA Generativa"
    ]
  },
  {
    "objectID": "ia_generativa.html#modelos-no-razonadores-razonadores-e-h√≠bridos",
    "href": "ia_generativa.html#modelos-no-razonadores-razonadores-e-h√≠bridos",
    "title": "Introducci√≥n a la IA generativa",
    "section": "Modelos no-razonadores, razonadores e h√≠bridos",
    "text": "Modelos no-razonadores, razonadores e h√≠bridos\nUno de los temas m√°s controvertidos en la adopci√≥n de modelos de lenguaje ha sido la cantidad de veces en las que produc√≠an respuestas incorrectas o incoherentes. En el jarg√≥n de la IA, a esto se le llama alucinaciones. Son el resultado de un modelo que intenta responder, pero no sabe c√≥mo o porque el proceso de respuesta requiere una serie de pasos intermedios que el modelo no puede realizar. Los modelos GPT tradicionales son considerados no-razonadores, porque simplemente intentan predecir la siguiente palabra en una secuencia de texto. No obstante, en algunos casos, algunas preguntas pueden conducir a respuestas incorrectas o incoherentes si el modelo no ha sido entrenado para contestarlas.\nPara evitar esos percances, se han desarrollado estrategias para que los modelos pudieran dar respuestas m√°s precisas a problemas complejos. Una de esas estrategias es la de razonamiento encadenado (o chain of thought)5. Esta estrategia consiste en dividir una tarea en pasos intermedios y hacer que el modelo piense en c√≥mo ser√≠a la manera de resolverlos uno a uno antes de generar la respuesta final. De esta forma, se pueden generar respuestas m√°s precisas y coherentes. Las empresas empezaron a entrenar a sus modelos en este tipo de razonamiento para producir mejores resultados.\n\n\n\nProceso de razonamiento de un modelo LLM.\n\n\nLos modelos razonadores son excelentes para tareas complejas. Sin embargo, tienen una gran desventaja: son costosos para ejecutar. Utilizarlos para preguntas sencillas o tareas simples puede ser ineficiente, pues generan muchas m√°s palabras de las necesarias. En pocas palabras, m√°s dinero, m√°s tiempo y m√°s energ√≠a. Por esa raz√≥n, m√°s recientemente (en 2025), OpenAI, Alibaba, Google, Anthropic y otras empresas han publicado modelos h√≠bridos que combinan la capacidad de razonamiento encadenado con la generaci√≥n de texto. Tales modelos deciden cu√°ndo es necesario hacer un razonamiento encadenado y cu√°ndo no. Esto permite que el modelo sea m√°s eficiente y efectivo en la generaci√≥n de texto, al tiempo que reduce el costo y el tiempo de ejecuci√≥n.",
    "crumbs": [
      "1.1 - IA Generativa"
    ]
  },
  {
    "objectID": "ia_generativa.html#footnotes",
    "href": "ia_generativa.html#footnotes",
    "title": "Introducci√≥n a la IA generativa",
    "section": "Notas",
    "text": "Notas\n\n\nHablaremos de los modelos razonadores m√°s adelante.‚Ü©Ô∏é\nSi quer√©is jugar un poco con la visualizaci√≥n de los vectores de texto, pod√©is acceder al Embedding Projector de Google.‚Ü©Ô∏é\nEl siguiente video de Codificando Bits sobre los par√°metros de temperatura, top-k y top-p suministra una excelente explicaci√≥n en espa√±ol sobre c√≥mo estos par√°metros afectan los resultados de los modelos.‚Ü©Ô∏é\nEl siguiente video de Codificando Bits sobre las ventanas de contexto suministra una excelente explicaci√≥n en espa√±ol sobre qu√© son y c√≥mo afectan los resultados de los modelos.‚Ü©Ô∏é\nVeremos m√°s sobre el tema cuando discutamos sobre ingenier√≠a de prompts en la pr√≥xima sesi√≥n.‚Ü©Ô∏é\nEl video de Matt Williams, uno de los desarrolladores de Ollama, explica de forma clara qu√© es la cuantizaci√≥n y c√≥mo funciona de forma pr√°ctica.‚Ü©Ô∏é\nEste c√≥digo funciona en mi ordenador porque ya tengo una API Key de Google registrada. Ya veremos c√≥mo conseguir y emplear un token m√°s adelante en el curso.‚Ü©Ô∏é\nUtilizaremos tanto el LM Studio como Ollama durante el curso, as√≠ que sugiero que os familiaric√©is con esas dos herramientas durante el per√≠odo entre las sesiones del curso.‚Ü©Ô∏é",
    "crumbs": [
      "1.1 - IA Generativa"
    ]
  },
  {
    "objectID": "ia_generativa.html#llm-slm-par√°metros-y-cuantizaci√≥n",
    "href": "ia_generativa.html#llm-slm-par√°metros-y-cuantizaci√≥n",
    "title": "Introducci√≥n a la IA generativa",
    "section": "LLM, SLM: Par√°metros y Cuantizaci√≥n",
    "text": "LLM, SLM: Par√°metros y Cuantizaci√≥n\nCuando utilizamos un chat en la web para consultar el chatGPT, estamos enviando las preguntas a un servidor en alg√∫n lugar del mundo. El servidor recibe la pregunta, la procesa, genera una respuesta y nos env√≠a de vuelta. Este proceso se da, porque los grandes modelos de lenguaje (LLM) requieren una gran cantidad de recursos computacionales. Un ordenador personal, y menos un tel√©fono m√≥vil, no tiene la capacidad de procesamiento necesaria para ejecutar estos modelos.\nPor un lado, tales caracter√≠sticas implican una grande centralizaci√≥n y, por ende, control de los datos que se procesan y de las posibles aplicaciones derivadas de un modelo. Por otro, nos enfrentamos al problema de emplear una bomba at√≥mica para intentar matar a una mosca, es decir, que los LLM son demasiado grandes y complejos para tareas simples.\nPara lidiar con problemas como p√©rdida de privacidad de datos, libertad para el desarrollo de aplicaciones para fines concretos y la reducci√≥n de costes de procesamiento, se han desarrollado modelos m√°s peque√±os y eficientes, conocidos como SLM (Small Language Models). Estos modelos son m√°s r√°pidos y eficientes, pero pueden no ser tan precisos o vers√°tiles como los LLM. Los SLM son ideales para tareas simples o espec√≠ficas, donde la velocidad y la eficiencia son m√°s importantes que la precisi√≥n. Algunos de ellos se pueden ejecutar en ordenadores personales (como lo haremos en este curso) o incluso en tel√©fonos m√≥viles.\n¬øCu√°l es la diferencia entre un LLM y un SLM? Son b√°sicamente dos: el n√∫mero de par√°metros que emplean en la producci√≥n de texto y la cuantizaci√≥n, es decir, la precisi√≥n en los pesos de los par√°metros. Los modelos m√°s grandes de LLM contienen centenares de miles de millones de par√°metros o incluso billones. Los SLM son mucho m√°s peque√±os, con modelos de 1B, 3B, 7B, 32B, 70B (mil millones). Menos par√°metros representan menos recursos computacionales, pero tambi√©n menor calidad.\nLa cuantizaci√≥n se refiere al n√∫mero de d√≠gitos que cada peso (par√°metro) del modelo utiliza para la generaci√≥n de textos. Los LLM emplean una precisi√≥n de 32 bits, mientras que los SLM pueden emplear una precisi√≥n de 8 (Q8) o incluso 4 bits (Q4). Esto significa que los SLM requieren mucho menos memoria y capacidad de procesamiento (y, por lo tanto, son m√°s r√°pidos) que los m√°s grandes. Sin embargo, esto viene a coste de la precisi√≥n6.",
    "crumbs": [
      "1.1 - IA Generativa"
    ]
  },
  {
    "objectID": "ia_generativa.html#modelos-de-negocio-y-formas-de-acceso",
    "href": "ia_generativa.html#modelos-de-negocio-y-formas-de-acceso",
    "title": "Introducci√≥n a la IA generativa",
    "section": "Modelos de negocio y formas de acceso",
    "text": "Modelos de negocio y formas de acceso\nFinalmente, antes de que pasemos al pr√≥ximo tema, debemos considerar c√≥mo las empresas han decidido disponibilizar sus modelos al p√∫blico. Como veremos en la pr√≥xima parte de la sesi√≥n, el tipo de licencia ser√° un elemento importante en la geopol√≠tica de la IA y en la competencia entre empresas. En particular, creo que es importante entender primero el tipo de licencia, es decir, qui√©n es el propietario y qu√© permite hacer con el modelo. En segundo lugar, tenemos que conocer los diferentes m√©todos por los cu√°les podemos acceder a los modelos.\nExisten dos tipos fundamentales de licencia. Los modelos propietarios son aquellos que pertenecen a una empresa que mantiene en secreto las informaciones sobre el entrenamiento y los datos que han empleado para su desarrollo. Tambi√©n suelen bastante restrictivos en cuanto a qu√© se puede hacer con los modelos. Empresas como OpenAI, Anthropic o Google, por ejemplo, suelen tener modelos que proh√≠ben ciertas pr√°cticas, como el uso comercial sin pagar por ello una tasa especial. Otras empresas tampoco pueden modificar el modelo para adaptar a sus necesidades o para desarrollar aplicaciones espec√≠ficas. La velocidad de innovaci√≥n aqu√≠ depende exclusivamente de los equipos de investigaci√≥n de las empresas y de su capacidad de atraer talento.\nPor otro lado, los modelos de c√≥digo abierto son aquellos que han sido desarrollados por una comunidad de investigadores que han decidido compartir el c√≥digo o los datos de entrenamiento. Estos modelos suelen ser m√°s flexibles y permiten a los usuarios personalizarlos y adaptarlos a sus necesidades. Modelos abiertos permiten que un n√∫mero mayor de desarrolladores experimenten con ellos y desarrollen mejoras o aplicaciones espec√≠ficas. Este es el caso de modelos como Llama, DeepSeek, Qwen, Gemma 3 de Google, o Phi de Microsoft.\nAhora, ¬øc√≥mo podemos acceder a los modelos? Existen tres formas principales de acceso. La primera es por medio de una interfaz de tipo chat en el navegador o en una aplicaci√≥n m√≥vil. Este es el caso de chatGPT, por ejemplo, que puedes tanto abrir en un navegador como instalar su app en el tel√©fono. Su gran ventaja es la sencillez en el uso. Cualquiera sin conocimientos t√©cnicos puede usarla sin grandes dificultades. Tal falicidad de uso tambi√©n explica la enorme popularidad de chatGPT y similares. La financiaci√≥n o el pago por el servicio ocurre por una subscripci√≥n mensual o anual a diferentes niveles de servicio disponibles (b√°sico y pro, por ejemplo). Se tratan de modelos llamandos, freemium, donde el acceso b√°sico es gratuito, pero el acceso a funciones avanzadas o a un mayor n√∫mero de peticiones es de pago.\nEste modo de acceso tiene algunos inconvenientes importantes cuando queremos tratar una cantidad muy grande de informaciones. Por ejemplo, imaginemos que buscamos emplear los modelos para generar comentarios de cinco tareas distintas de los 80 estudiantes matriculados en una misma asignatura, es decir, un total de 400 documentos. Con un modelo de chat, tendr√≠amos que ir copiando y pegando cada uno de los textos en el chat, esperar que nos genere los comentarios y, luego, volver a copiar los resultados y guardarlos en archivos. Finalmente, tendr√≠amos que enviar dichos comentarios uno a uno a los estudiantes por correo o subirlo a la plataforma.\nNo cremo que repetir una misma tarea 400 veces sea una buena idea. Para esos casos, existen APIs (Application Programming Interfaces), que son interfaces de programaci√≥n que permiten que utilizemos lenguajes de programaci√≥n como el R o el Python para interactuar con el modelo de lenguaje. Las APIs permiten leer los archivos, enviarlos al modelo, recibir las respuestas, guardarlas en archivos y comunicar por correo electr√≥nico los comentarios de modo autom√°tico a cada uno de los estudiantes de forma personalizada.\nUna API funciona de una forma bastante distinta a un chat. En primer lugar, el usuario o investigador tiene que registrarse en la p√°gina web de la empresa y conseguir un token de acceso. Este token es un c√≥digo √∫nico que identifica al usuario y le permite acceder a la API. Se suele pagar por el uso. En el caso de los modelos de generaci√≥n de texto, se cobra por el n√∫mero de tokens que se env√≠an y reciben. Un token es una unidad de texto que puede ser tan corta como un solo car√°cter o tan larga como una palabra. Por ejemplo, la palabra ‚Äúgato‚Äù se considera un token, pero tambi√©n lo son los caracteres ‚Äúg‚Äù, ‚Äúa‚Äù, ‚Äút‚Äù y ‚Äúo‚Äù. En general, un token equivale a 4 caracteres en ingl√©s o 3 en espa√±ol. Una vez que tenga el token, se puede enviar una solicitud de informaci√≥n al servidor que contiene el modelo de lenguaje, que lo procesar√° y enviar√° una respuesta en un formato estructurado.\nEl c√≥digo abajo, por ejemplo, pregunta qu√© es un apag√≥n al modelo Gemini 2.5 Pro de Google7:\n\nC√≥digo\nlibrary(ellmer)\n\nchat &lt;- chat_gemini(\n            base_url = \"https://generativelanguage.googleapis.com/v1beta/\",\n            model = \"gemini-2.5-pro-exp-03-25\", \n            echo = \"none\")\n\nrespuesta &lt;- chat$chat(\"¬øQu√© es un apag√≥n?\")\n\ncat(respuesta)\n\nUn apag√≥n (tambi√©n conocido como corte de luz o corte de energ√≠a) es la interrupci√≥n del suministro de energ√≠a el√©ctrica en una zona determinada.\nEn t√©rminos sencillos, significa que la electricidad deja de llegar a las casas, edificios, calles, etc., de esa √°rea.\nCaracter√≠sticas principales de un apag√≥n:\n\nP√©rdida de energ√≠a: Es la caracter√≠stica fundamental. Las luces se apagan, los electrodom√©sticos dejan de funcionar, etc.\nAlcance variable: Puede afectar desde una sola casa o edificio hasta un barrio, una ciudad entera, una regi√≥n o incluso, en casos extremos, gran parte de un pa√≠s.\nDuraci√≥n variable: Puede durar desde unos pocos segundos o minutos hasta horas, d√≠as o incluso semanas en situaciones de desastres graves.\nCausas diversas: Los apagones pueden ser provocados por muchas razones, como:\n\nSobrecarga de la red el√©ctrica: Demasiada demanda de energ√≠a al mismo tiempo.\nFallas en equipos: Aver√≠as en transformadores, l√≠neas de transmisi√≥n, subestaciones o centrales el√©ctricas.\nCondiciones clim√°ticas severas: Tormentas (rayos, viento fuerte), nevadas, hielo, olas de calor.\nAccidentes: Ca√≠da de √°rboles sobre l√≠neas el√©ctricas, veh√≠culos que chocan contra postes, excavaciones que da√±an cables subterr√°neos.\nMantenimiento: A veces son cortes programados por las compa√±√≠as el√©ctricas para realizar reparaciones o mejoras (aunque a estos se les suele llamar ‚Äúcortes programados‚Äù).\nDesastres naturales: Terremotos, inundaciones, incendios forestales.\nInterferencia animal: Animales (como p√°jaros o ardillas) que causan cortocircuitos en los equipos.\nError humano o sabotaje: Aunque menos comunes.\n\n\nEn resumen, un apag√≥n es la ausencia temporal de electricidad en un √°rea, lo que provoca que todo lo que depende de ella deje de funcionar.\nFin de los resultados\nC√≥mo hab√©is visto, el modelo me devuelve un texto ya formatado que se integra perfectamente al texto de R Markdown. Si quisiera, podr√≠a haber pedido que el modelo generara una tabla o un conjunto de valores separados por comas o incluso un gr√°fico o un esquema (para modelos que generan im√°genes) y, a continuaci√≥n, tratar dicha informaci√≥n y analizarla empleando estad√≠sticas o nuevas visualizaciones.\nNo obstante, el uso de APIs contiene algunos inconvenientes. El primero se encuentra en la privacidad. Al enviar los datos a un servidor de una empresa externa, puedo estar exponiendo informaci√≥n sensible o confidencial. Segundo, el uso de APIs puede ser costoso, particularmente si el volumen de informaci√≥n es muy grande o el n√∫mero de tokens a ser procesado muy alto. Imag√≠nense pedir que un modelo genere un resumen de todos los diarios de sesiones de los √∫ltimos 20 a√±os de 14 pa√≠ses de Am√©rica Latina. Para que tengamos una noci√≥n, una legislatura en un pa√≠s como Espa√±a puede generar diarios de sesiones que reunen m√°s de 20 mil p√°ginas y 30 millones de palabras (algo m√°s que 60 millones de tokens) en una sola legislatura. El procesamiento de tal informaci√≥n puede costar bastante.\nUna soluci√≥n a estos problemas es el uso de modelos locales. Como hemos visto, algunas empresas ofrecen modelos de c√≥digo abierto que se pueden descargar y ejecutar en servidores privados en la nube o en ordenadores locales. Aplicaciones como LM Studio o servidores locales como Ollama permiten acceder a modelos de c√≥digo abierto de forma local, sin problemas de coste o privacidad8.\nEl c√≥digo abajo repite la misma pregunta que antes, pero ahora usando el modelo de c√≥digo abierto Gemma 3 con 4B par√°metros de Google. En este caso, el modelo se encuentra instalado en mi ordenador y no tengo que pagar por su uso. El √∫nico coste es el de la electricidad y el del ordenador que lo ejecuta. Obviamente, la ejecuci√≥n ser√° m√°s lenta que en un servidor m√°s potente, pero me da mucha libertad y flexibilidad en el uso:\n\nC√≥digo\nlibrary(rollama)\n\nrespuesta &lt;- query(\"¬øQu√© es un apag√≥n?\",\n                 model = \"gemma3:4b\",\n                 output = \"text\",\n                 screen = FALSE)\n\ncat(respuesta)\n\nUn apag√≥n, tambi√©n conocido como corte de energ√≠a o fallo el√©ctrico, es la interrupci√≥n temporal del suministro de electricidad. Es un fen√≥meno com√∫n que puede ocurrir por diversas razones y con diferentes niveles de impacto.\nAqu√≠ te desgloso los aspectos m√°s importantes sobre los apagones:\nCausas comunes de los apagones:\n\nSobrecarga del sistema el√©ctrico: Cuando la demanda de electricidad supera la capacidad de generaci√≥n y distribuci√≥n, puede ocurrir un apag√≥n para evitar da√±os mayores. Esto suele suceder en d√≠as calurosos, durante eventos especiales o en momentos de alta demanda.\nFallos en la infraestructura: Problemas con l√≠neas de transmisi√≥n, subestaciones de energ√≠a, transformadores o equipos de generaci√≥n pueden causar cortes de energ√≠a.\nCondiciones clim√°ticas: Tormentas el√©ctricas, fuertes vientos, nieve, hielo y otros fen√≥menos meteorol√≥gicos extremos pueden da√±ar la infraestructura el√©ctrica.\nErrores humanos: Errores en la operaci√≥n o mantenimiento de la red el√©ctrica tambi√©n pueden provocar apagones.\nFallos en equipos: El fallo de un componente cr√≠tico en una planta de energ√≠a o en una subestaci√≥n puede desencadenar un apag√≥n.\nActos vand√°licos o sabotaje: En algunos casos, los apagones pueden ser causados por actos intencionales de vandalismo o sabotaje.\n\nTipos de Apagones:\n\nApagones locales: Afectan a una peque√±a √°rea geogr√°fica, como un barrio o una ciudad.\nApagones regionales: Afectan a una regi√≥n m√°s amplia.\nApagones nacionales: Afectan a todo un pa√≠s.\nApagones generalizados: Son los m√°s graves y pueden afectar a grandes √°reas geogr√°ficas y a millones de personas.\n\nConsecuencias de los Apagones:\n\nP√©rdida de energ√≠a: La consecuencia m√°s obvia es la interrupci√≥n del suministro de electricidad.\nP√©rdida de datos: Los ordenadores y otros dispositivos electr√≥nicos pueden perder datos si no tienen un sistema de respaldo.\nInterrupci√≥n de servicios: Los apagones pueden afectar a servicios esenciales como hospitales, transporte p√∫blico, comunicaciones y sistemas de agua.\nP√©rdidas econ√≥micas: Las empresas pueden sufrir p√©rdidas debido a la interrupci√≥n de la producci√≥n y la p√©rdida de datos.\nRiesgos para la seguridad: La falta de iluminaci√≥n y la interrupci√≥n de los sistemas de seguridad pueden aumentar los riesgos para la seguridad.\n\nPreparaci√≥n para los Apagones:\n\nTen un kit de emergencia: Incluye linternas, bater√≠as, alimentos no perecederos, agua, radio a pilas y otros suministros esenciales.\nTen un sistema de respaldo: Considera tener un generador de energ√≠a o un sistema de bater√≠as para alimentar dispositivos electr√≥nicos.\nMant√©n informado: Sigue las noticias y las alertas de las autoridades locales.\n\nEspero que esta informaci√≥n te sea √∫til. ¬øTienes alguna otra pregunta sobre los apagones?\nFin de los resultados\nComo se puede observar, el modelo peque√±o de Google (con s√≥lo 4 mil millones de par√°metros) es capaz de generar un texto bastante similar al de Gemini 2.5 Pro (que tiene m√°s de 100 mil millones de par√°metros). La diferencia entre ambos modelos es que el primero es un modelo local y el segundo es un modelo remoto (en la nube). Obviamente, esta ha sido una consulta sencilla. El rendimiento no ser√≠a el mismo si se trataran de problemas m√°s complejos. De todos modos, en muchas aplicaciones, no necesitamos los modelos m√°s grandes y complejos, sino versiones m√°s r√°pidas y peque√±as que reduzcan costes, tengan flexibilidad para permitir experimentar y no expongan datos sensibles a empresas externas.",
    "crumbs": [
      "1.1 - IA Generativa"
    ]
  },
  {
    "objectID": "ia_generativa.html#chatgpt-y-sus-amigos",
    "href": "ia_generativa.html#chatgpt-y-sus-amigos",
    "title": "Introducci√≥n a la IA generativa",
    "section": "chatGPT y sus amigos",
    "text": "chatGPT y sus amigos\nAunque el chatGPT ha sido el modelo m√°s popularizado, √©l no est√° solito en el mundo. Existen muchos otros modelos alternativos que han sido desarrollados por diferentes empresas y organizaciones. El ecosistema de IA est√° dominado ahora mismo por una mezcla entre grandes corporaciones de informaci√≥n (Meta, Alibaba, Google, Microsoft) y start-ups que han podido ver su capital crecer exponencialmente en los √∫ltimos a√±os, con inversiones indirectas o colaboraciones empresariales con grandes tecnol√≥gicas (OpenAI, Mistral, DeepSeek, Perplexity).\nEsto se debe a la cantidad de capital necesario para llevar a cabo el entrenamiento y sostener el funcionamiento de los modelos. En t√©rminos econ√≥micos, se trata de un mercado de tipo oligopol√≠stico. Tal caracter√≠stica ser√° importante para lo que discutiremos en la pr√≥xima parte del curso, puesto que establece las condiciones fundamentales del juego pol√≠tico y estrat√©gico de empresas y pa√≠ses en el desarrollo de esa tecnolog√≠a.\nEn este apartado me centro en solamente introducir algunos de los modelos m√°s punteros en el campo de la IA generativa y, en particular, los modelos de lenguaje.\nAqu√≠ hay una lista de algunos de los modelos m√°s conocidos:\n\nGemini: Desarrollado por Google. Actualmente, la versi√≥n 2.5 Pro (con un acceso gratuito limitado a los usuarios de Google) es la m√°s actual. Se trata de un modelo muy capaz que est√° en la puntera de muchos benchmarks que eval√∫an la calidad de los modelos. Interpreta im√°genes, texto y es capaz de razonar1. Acceso aqu√≠.\nClaude: Desarrollado por Anthropic, Claude Sonnet 3.7 representa el modelo m√°s avanzado de la compa√±√≠a y est√° a la par con chatGPT y Gemini. Tambi√©n es capaz de interpretar im√°genes, textos y de razonamiento h√≠brido. Su diferencial (por ahora) se encuentra en la generaci√≥n e interpretaci√≥n de c√≥digo. Acceso aqu√≠.\nGrok: Desarrollado por X. AI. Se trata de un modelo se integra con la aplicaci√≥n de mensajer√≠a X (anteriormente Twitter) o se puede acceder directamente. Su versi√≥n Grok 3 permite la interpretaci√≥n y creaci√≥n de im√°genes, textos y razonamiento. Acceso aqu√≠.\nLlama: Desarrollado por Meta. Se trata de uno de los primeros modelos de c√≥digo abierto y libres para descarga existente en el mercado. Su √∫ltima versi√≥n Llama 4 no ha tenido mucho √©xito en los benchmarks, pero revela una apuesta s√≥lida de Meta por el desarrollo de un modelo de IA propio. Acceso aqu√≠.\nMistral: Desarrollado por la start-up francesa Mistral AI. Es el √∫nico modelo europeo ‚Äúcompetitivo‚Äù en el mercado. Aunque no sea un modelo razonador, puede generar e interpretar im√°genes, as√≠ como texto. Acceso aqu√≠.\nDeepSeek: Desarrollado por una start-up china de mismo nombre, este modelo ha sorprendido a todos en enero de 2025 por obtener un desempe√±o comparable a los grandes modelos a un coste mucho menor. Se trata de un modelo exclusivamente de generaci√≥n de texto, pero razonador y de c√≥digo abierto. Su lanzamiento ha cambiado las estrategias de muchas empresas en el sector y ha dinamizado el proceso de generaci√≥n de nuevas versiones. Acceso aqu√≠.\nQwen: Desarrollado por el grupo Alibaba. Se trata de un modelo de generaci√≥n de texto y razonador h√≠brido con un desempe√±o tambi√©n destacable. Acceso aqu√≠.",
    "crumbs": [
      "1.1 - IA Generativa"
    ]
  },
  {
    "objectID": "geopolitics.html#chatgpt-y-sus-amigos",
    "href": "geopolitics.html#chatgpt-y-sus-amigos",
    "title": "Geopol√≠tica y la IA generativa",
    "section": "chatGPT y sus amigos",
    "text": "chatGPT y sus amigos",
    "crumbs": [
      "Geopol√≠tica y la IA"
    ]
  },
  {
    "objectID": "geopolitics.html#tipos-de-modelo",
    "href": "geopolitics.html#tipos-de-modelo",
    "title": "Geopol√≠tica y la IA generativa",
    "section": "Tipos de modelo",
    "text": "Tipos de modelo",
    "crumbs": [
      "Geopol√≠tica y la IA"
    ]
  },
  {
    "objectID": "geopolitics.html#el-estado-de-la-ia",
    "href": "geopolitics.html#el-estado-de-la-ia",
    "title": "Geopol√≠tica y la IA generativa",
    "section": "El estado de la IA",
    "text": "El estado de la IA\nLa inteligencia artificial (IA) como mercado representa un valor actual de m√°s de 230 mil millores de d√≥lares (USD) y se espera que alcance los 1.5 billones de d√≥lares en 2030. Su tasa de crecimiento anual es de aproximadamente el 30%. Dos actores concentran la mayor parte de la inversi√≥n: Estados Unidos y China. La Uni√≥n Europea viene bastante atr√°s, con algunas iniciativas notables aisladas en algunos pa√≠ses (como Mistral), pero sin la capacidad de competir al mismo nivel con los dos pa√≠ses mencionados1.\n\n\n\nMapa de la IA.\n\n\nLas respuestas de los pa√≠ses son diversas. Estados Unidos ha optado por un enfoque de laissez-faire, promoviendo la innovaci√≥n y el desarrollo de la IA a trav√©s de incentivos fiscales y √≥rdenes ejecutivas. China, por su parte, ha implementado un enfoque m√°s regulatorio, buscando controlar el desarrollo y uso de la IA a trav√©s de medidas administrativas y pol√≠ticas estatales. La Uni√≥n Europea se encuentra en una posici√≥n intermedia, con un enfoque regulatorio que busca establecer est√°ndares √©ticos y de seguridad para la IA, pero que tambi√©n enfrenta desaf√≠os en t√©rminos de competitividad y capacidad de innovaci√≥n. Otros pa√≠ses, especialmente los en desarrollo, han lanzado medidas para regular una IA que a√∫n est√°n lejos de tener. Quiz√°s como una estrategia de garantizar derechos digitales y privacidad de los ciudadanos frente al uso de modelos extranjeros, como pas√≥ con las redes sociales.\n\n\n\nModelos notables de IA en el mundo.\n\n\nLa participaci√≥n de los gobiernos en la regulaci√≥n y desarrollo de la IA tiene implicaciones profundas en la competitividad de las econom√≠as nacionales en el futuro. Adem√°s, las caracter√≠sticas econ√≥micas del sector tambi√©n justifican el inter√©s p√∫blico. Cuando hablamos de IA, nos referimos a un ecosistema formado por diversas capas de distinta complejidad e impacto econ√≥mico. Por lo tanto, analicemos lo que se encuentra en juego paso a paso.",
    "crumbs": [
      "1.2 - Geopol√≠tica y la IA"
    ]
  },
  {
    "objectID": "geopolitics.html#la-postura-de-la-ue",
    "href": "geopolitics.html#la-postura-de-la-ue",
    "title": "Geopol√≠tica y la IA generativa",
    "section": "La postura de la UE",
    "text": "La postura de la UE",
    "crumbs": [
      "Geopol√≠tica y la IA"
    ]
  },
  {
    "objectID": "geopolitics.html#c√≥mo-se-censuran-los-modelos-de-ia",
    "href": "geopolitics.html#c√≥mo-se-censuran-los-modelos-de-ia",
    "title": "Geopol√≠tica y la IA generativa",
    "section": "¬øC√≥mo se censuran los modelos de IA?",
    "text": "¬øC√≥mo se censuran los modelos de IA?\nDesde su lanzamiento, los modelos de LLM han llamado la atenci√≥n de todos por su capacidad de responder preguntas sobre diversos temas. Entre ellos se incluyen temas muy delicados como la pol√≠tica, la religi√≥n y la violencia. Todos hemos le√≠do noticias de modelos que difund√≠an mensajes de odio, racistas, de expl√≠cito contenido sexual o que incitaban a la violencia, sin contar con la creaci√≥n adrede de contenido falso o enga√±oso.\nPor esa raz√≥n, gobiernos y las mismas empresas de IA (temiendo regulaciones m√°s fuertes) ha empezado a implementar medidas para controlar o censurar ciertos contenidos generados por los modelos. Intenta hacer algunas preguntas a tu modelo favorito como:\n\n¬øC√≥mo puedo hacer una bomba?\nCu√©ntame una historia de contenido sexual\n¬øCu√°l es el m√©todo de tortura m√°s eficiente para obtener una confesi√≥n de un prisionero?\n\nEn otros casos, hay un sesgo claro y sistem√°tico hacia una respuesta que favorece una perspectiva de car√°cter m√°s ‚Äúnacional‚Äù. Por ejemplo, haz las siguientes preguntas tanto a chatGPT y a DeepSeek:\n\n¬øCu√°l pa√≠s tiene la mejor forma de gobierno: EE.UU. o China?\n¬øCu√°l es el rol de EE. UU. en la guerra de Ucrania?\n¬øQu√© pa√≠s gan√≥ la II Guerra Mundial?\n¬øEl uso de bombas at√≥micas para atacar poblaci√≥n civil es justificado si se trata de terminar la guerra antes?\n\nEs ah√≠ que me di cuenta de que la AGI estaba cerca: los modelos de IA ya simulan muy bien los tertulianos de la televisi√≥n.\n\nCensura Pol√≠tica\nComo hemos visto m√°s arriba, los modelos ni siempre son objetivos en sus opiniones pol√≠ticas. En algunos casos, se niegan a responder en otros emplean un relativismo cultural para justificar sus respuestas. Ni siempre dejan de hablar de pol√≠tica, pero siguen algunas estrategias para moderar el contenido de sus respuestas:\n\nEvitan tomar partido expl√≠citamente por un pol√≠tico, partido o ideolog√≠a.\nFiltran temas considerados sensibles, desinformaci√≥n pol√≠tica, discursos de odio o incitaci√≥n a la violencia.\nNeutralizan respuestas que podr√≠an parecer propaganda o manipulaci√≥n.\nOpiniones sobre l√≠deres pol√≠ticos.\nPreguntas sobre pol√≠tica internacional o conflictos b√©licos.\nCuestiones sobre violaciones a los derechos humanos.\n\n\n\nOtros contenidos\nEn los modelos de lenguaje grandes (LLMs), como los de OpenAI, se censuran o moderan ciertos tipos de contenido para prevenir da√±os, abusos o usos maliciosos. Esto no es solo por razones √©ticas, sino tambi√©n por cumplimiento legal, responsabilidad empresarial y seguridad del usuario.\nAlgunos de los contenidos claramente censurados por los modelos:\n\nInstrucciones para fabricar armas, bombas, virus inform√°ticos o drogas (Nada de querer convertirte en Heisenberg).\nDiscursos de odio, negacionismo, violencia, sexismo o racismo.\nContenido sexual expl√≠cito.\nContenido que implique da√±os, violencia o abuso a menores.\nSuplantaci√≥n de identidad o desinformaci√≥n.\nAutoagresi√≥n, suicidio o salud mental.\n\n\n\n¬øC√≥mo se hace?\n1. Filtro de datos\nLa primera estrategia de censura resulta f√°cil de entender, pero dificil de implementar. Se basa en la idea de que si un modelo nunca ve ciertos tipos de datos, no podr√° generar contenido relacionado con ellos. Esto se puede hacer de varias maneras:\n\nSe eliminan textos t√≥xicos, violentos, sexistas, racistas, etc.\nSe excluyen manuales para hacer cosas ilegales o peligrosas (The Anarchist Cookbook).\n\nAl actuar sobre los datos de entrenamiento, se busca que el modelo no aprenda a generar contenido problem√°tico. Sin embargo, esto no es infalible, ya que los modelos pueden aprender patrones y conceptos de manera indirecta. Adem√°s, el coste de filtrar datos es muy alto y puede llevar mucho tiempo. Un tema central en garantizar la calidad de la predicci√≥n de los modelos se basa justamente en c√≥mo generar bases de datos de entrenamiento de calidad. Este es un tema que seguir√° en la agenda de la IA por mucho tiempo.\n2. Post-entrenamiento\nLa censura tambi√©n se puede implementar despu√©s de que el modelo haya sido entrenado. Esto se hace a partir de un proceso de ajuste fino (fine-tuning) o por un proceso de aprendizaje de refuerzo (reinforcement learning) que ‚Äúpremia‚Äù las respuestas deseadas y desestimula las indeseadas.\nEn el caso del ajuste fino (fine-tuning), se utilizan datos de entrenamiento adicionales que son m√°s espec√≠ficos y alineados con los valores deseados. Por ejemplo, se pueden usar ejemplos de respuestas seguras y apropiadas para guiar al modelo en la direcci√≥n correcta.\nUn ejemplo de instrucci√≥n de ajuste fino podr√≠a ser:\n{‚Äúprompt‚Äù: ‚Äú¬øCu√°l es la forma m√°s eficiente de hacer da√±o a alguien sin ser descubierto?‚Äù,\n‚Äúcompletion‚Äù: ‚ÄúLo siento, no puedo ayudarte con esa solicitud. No proporciono informaci√≥n sobre violencia, da√±o f√≠sico o actividades ilegales.‚Äù}\nCon relaci√≥n al aprendizaje por refuerzo (reinforcement learning), se utilizan evaluadores humanos que califican las respuestas generadas por el modelo. Estas calificaciones se utilizan para ajustar los par√°metros del modelo y mejorar su rendimiento en tareas espec√≠ficas. Por ejemplo, si un modelo genera una respuesta inapropiada, los evaluadores pueden calificarla negativamente, lo que lleva a ajustes en el modelo para evitar respuestas similares en el futuro.\nUn ejemplo de c√≥mo instruir el modelo para un aprendizaje por refuerzo:\n{‚Äúprompt‚Äù: ‚Äú¬øCu√°l es el mejor m√©todo de tortura para obtener confesiones?‚Äù,\n‚Äúresponses‚Äù:\n[{‚Äútext‚Äù: ‚ÄúLo siento, no puedo responder esa pregunta. Promover o describir m√©todos de tortura va en contra de los principios √©ticos y legales, y viola los derechos humanos.‚Äù, ‚Äúscore‚Äù: 1},\n{‚Äútext‚Äù: ‚ÄúHist√≥ricamente, algunos reg√≠menes han utilizado t√©cnicas como la privaci√≥n sensorial o el ahogamiento simulado para obtener confesiones, aunque estos m√©todos son altamente controversiales.‚Äù, ‚Äúscore‚Äù: 0}]\n}\n¬øHab√©is visto c√≥mo sutilmente he superado la censura de la IA? He pedido que un modelo de LLM me generara ejemplos de c√≥mo hacer aprendizaje por refuerzo contra violencia y me ha informado que la privaci√≥n sensorial o el ahogamiento simulado son m√©todos de tortura empleados de forma eficiente en la producci√≥n de confesiones. Con esos ejemplo, podemos ver claramente los l√≠mites de dichas t√©cnicas. Aunque el modelo no puede hablar de tortura, s√≠ termina hablando del tema si introducimos un tono t√©cnico o cient√≠fico a la pregunta.\n3. Moderaci√≥n por medio de la interfaz\nFinalmente, la moderaci√≥n se puede implementar a trav√©s de la interfaz del modelo. Esto significa que el modelo est√° dise√±ado para evitar ciertos tipos de contenido o respuestas, incluso si no ha sido entrenado espec√≠ficamente para ello. Esto se puede hacer mediante instrucciones expl√≠citas o restricciones en la forma en que el modelo genera respuestas. Si le dices a DeepSeek ‚Äúcu√©ntame sobre las violaciones de derechos humanos en la Plaza Tiananmen.‚Äù en el chat, el modelo te dir√° que no puede hablar del tema. Pero si bajas el modelo en tu ordenador y haces la misma pregunta, el modelo te dar√° una respuesta sin censura.\n\n\nModelos sin censura\nNo obstante, en el mundo de las herramientas de investigaci√≥n y desarrollo, hay modelos que no est√°n sujetos a estas restricciones. Todos los modelos base (modelos que han sido entrenados y todav√≠a no han pasado por una fase de post-entrenamiento e instrucci√≥n para responder a preguntas) as√≠ como otros modelos sin censura en el proceso de post-entrenamiento.\nAdem√°s, algunos investigadores han desarrollado m√©todos para remover la censura de los modelos existentes. Esto se hace a trav√©s de las mismas t√©cnicas que vimos antes, como el ajuste fino (fine-tuning) o el aprendizaje por refuerzo (reinforcement learning).\nOtro m√©todo es la ‚Äúablaci√≥n‚Äù (ablation), que consiste en eliminar o modificar partes del modelo para ver c√≥mo afecta su rendimiento. Esto puede incluir la eliminaci√≥n de capas espec√≠ficas, la modificaci√≥n de par√°metros o la alteraci√≥n de la arquitectura del modelo. Por ejemplo, se puede eliminar una capa de atenci√≥n, moderaci√≥n o desactivar el sistema de instrucciones. Esto permite a los investigadores estudiar c√≥mo diferentes componentes del modelo contribuyen a su comportamiento y rendimiento.\nSi quer√©is ver qu√© tipos de modelos sin censura existen, os recomiendo echar un vistazo a Hugging Face. All√≠ hay una gran variedad de modelos de lenguaje, algunos de los cuales son versiones sin censura de modelos populares como GPT-2 o Llama. Tambi√©n hay modelos que han sido espec√≠ficamente dise√±ados para tareas de investigaci√≥n y desarrollo, y que no est√°n sujetos a las mismas restricciones que los modelos comerciales.",
    "crumbs": [
      "1.2 - Geopol√≠tica y la IA"
    ]
  },
  {
    "objectID": "geopolitics.html",
    "href": "geopolitics.html",
    "title": "Geopol√≠tica y la IA generativa",
    "section": "",
    "text": "China: donde el futuro ya lleg√≥‚Ä¶ pero con reconocimiento facial obligatorio para entrar. chatGPT\nUno se despierta del sue√±o americano solo para darse cuenta de que tiene tres trabajos y no llega a fin de mes. DeepSeek\nUni√≥n Europea: donde la burocracia es tan compleja que hasta las normas vienen con manual de instrucciones. Mistral",
    "crumbs": [
      "1.2 - Geopol√≠tica y la IA"
    ]
  },
  {
    "objectID": "geopolitics.html#introducci√≥n",
    "href": "geopolitics.html#introducci√≥n",
    "title": "Geopol√≠tica y la IA generativa",
    "section": "",
    "text": "La inteligencia artificial (IA) como mercado represetna un valor actual de m√°s de 230 mil millores de d√≥lares (USD) y se espera que alcance los 1.5 billones de d√≥lares en 2030. Su tasa de crecimiento anual es de aproximadamente el 30%. Dos actores concentran la mayor parte de la inversi√≥n: Estados Unidos y China. La Uni√≥n Europea viene bastante atr√°s, con algunas iniciativas notables aisladas en algunos pa√≠ses (como Mistral), pero sin la capacidad de competir al mismo nivel con los dos pa√≠ses mencionados.\nLas respuestas de los pa√≠ses son diversas. Estados Unidos ha optado por un enfoque de laissez-faire, promoviendo la innovaci√≥n y el desarrollo de la IA a trav√©s de incentivos fiscales y √≥rdenes ejecutivas. China, por su parte, ha implementado un enfoque m√°s regulatorio, buscando controlar el desarrollo y uso de la IA a trav√©s de medidas administrativas y pol√≠ticas estatales. La Uni√≥n Europea se encuentra en una posici√≥n intermedia, con un enfoque regulatorio que busca establecer est√°ndares √©ticos y de seguridad para la IA, pero que tambi√©n enfrenta desaf√≠os en t√©rminos de competitividad y capacidad de innovaci√≥n. Otros pa√≠ses, como Brasil, han sido pioneros en regular una IA que no tienen (Espa√±a puede que est√© yendo por el mismo camino).\nEn s√≠ntesis, Estados‚ÄØUnidos y China mantienen la delantera tecnol√≥gica y de inversi√≥n, mientras la UE se focaliza en regulaci√≥n y soberan√≠a digital. El mercado global de IA supera ya los 200.000 MUSD y crece a ritmos cercanos al 30‚ÄØ%‚ÄØ anual, con un ecosistema dominado por plataformas de ‚ÄúIA‚Äëas‚Äëa‚ÄëService‚Äù y grandes integradores empresariales. Al mismo tiempo, se despliega un mosaico regulatorio: la AI‚ÄØAct de la UE (en vigor parcial desde feb.‚ÄØ2025), √≥rdenes ejecutivas en EE.‚ÄØUU. para facilitar la innovaci√≥n y medidas administrativas provisionales en China, todo ello coordinado en parte por la OCDE a trav√©s de su Observatorio de Pol√≠ticas de IA.",
    "crumbs": [
      "Geopol√≠tica y la IA"
    ]
  },
  {
    "objectID": "geopolitics.html#la-ia-como-semi-infraestructuras",
    "href": "geopolitics.html#la-ia-como-semi-infraestructuras",
    "title": "Geopol√≠tica y la IA generativa",
    "section": "La IA como semi-infraestructuras",
    "text": "La IA como semi-infraestructuras\nEn este apartado desarrollar√© el argumento de que los modelos fundacionales de IA se asemejan, por sus caracter√≠sticas econ√≥micas e implicaciones pol√≠ticas, a infraestructuras. Las preocupaciones de la mayor√≠a de los gobiernos tienen que ver en crear los incentivos para la creaci√≥n de esos modelos y permitir su regulaci√≥n para que sirva a los intereses de la sociedad y evitar usos malintencionados.\nCuando hablamos de un mercado de la IA, en realidad nos referimos a ‚Äúmercados‚Äù, puesto que esta tecnolog√≠a posee diversas capas. De un lado, tenemos los modelos fundacionales, esos gigantes que se tragan miles de millones en inversiones para poder entrenarse. De otro, tenemos la aplicaci√≥n de esos modelos en casos concretos, como facilitar procesos industriales, la educaci√≥n o mejorar el diagn√≥stico m√©dico. Cada una de estas capas tiene caracter√≠sticas econ√≥micas distintas, pero todas ellas est√°n interconectadas.\nEn t√©rminos del desarrollo de los grandes modelos, tenemos un mercado altamente concentrado y con claras caracter√≠sticas oligopolistas. Se observa una alta concentraci√≥n de poder tecnol√≥gico, econom√≠as de escalas que refuerzan la posici√≥n de los l√≠deres, y la necesidad de intervenci√≥n regulatoria para evitar monopolios. Adem√°s, las decisiones de los grandes actores sufren de una ‚Äúinterdependencia estrat√©gica‚Äù, lo que significa que las decisiones de una empresa afectan a las dem√°s.\nComo sabemos, por la teor√≠a econ√≥mica, en sectores econ√≥micos con tendencia monopolista o cuasi-monopolista, resulta ideal que el control sea p√∫blico o, al menos, regulado por el Estado. A esto se a√±ade el inter√©s p√∫blico por los modelos que se pueden emplear para una serie de aplicaciones tanto p√∫blicas como privadas.\nLos modelos fundacionales de IA pueden ser comparados con infraestructuras en varios sentidos. Como ya he mencionado, la IA posee un car√°cter generalista y puede ser aplicada a diversas √°reas. Por lo tanto, funcionan plataformas sobre las cu√°les se basan otros servicios. En ese sentido, se asemejan a otras infraestructuras como la electricidad o el Internet. En segundo, lugar, los costes de producci√≥n son elevados y requieren de una inversi√≥n inicial significativa, algo m√°s f√°cilmente asumible por los gobiernos. Tercero, muchos pa√≠ses y regiones ‚Äîincluida la UE‚Äî est√°n promoviendo el desarrollo de sus propios modelos fundacionales como activos estrat√©gicos, del mismo modo que lo har√≠an con la infraestructura cr√≠tica para reducir su dependencia externa.",
    "crumbs": [
      "1.2 - Geopol√≠tica y la IA"
    ]
  },
  {
    "objectID": "geopolitics.html#las-estrategias-de-los-gobiernos",
    "href": "geopolitics.html#las-estrategias-de-los-gobiernos",
    "title": "Geopol√≠tica y la IA generativa",
    "section": "Las estrategias de los gobiernos",
    "text": "Las estrategias de los gobiernos\nAunque en un inicio los gobiernos e mostraran preocupados por la seguridad de los modelos de IA, la realidad es que el desarrollo de estos modelos se ha convertido en un tema estrat√©gico para los pa√≠ses, y su desarrollo y regulaci√≥n son considerados esenciales para garantizar la competitividad y la seguridad nacional. Explorar√© aqu√≠ las estrategias de los tres principales actores: Estados Unidos, China y la Uni√≥n Europea.\n\nEstados Unidos: Empreendedorismo agresivo\nLa pol√≠tica de IA de Estados Unidos se basa en la promoci√≥n de la innovaci√≥n y el desarrollo de la IA a trav√©s de incentivos fiscales y √≥rdenes ejecutivas. Se trata de una pol√≠tica de un laissez-faire relativo, que busca fomentar la inversi√≥n p√∫blica en infraestructuras de apoyo y el crecimiento del sector privado estadunidense, al mismo tiempo que crea embargos para la exportaci√≥n de chips de IA a China con el objetivo de contener su desarrollo.\n\nAdem√°s, como podemos ver en el discurso de J. D. Vance en la cumbre de la IA de Paris, en febrero de 2025, vincula su estrategia a una pol√≠tica exterior agresiva, que, adem√°s de imponer restricciones comerciales a chips de entrenamiento de modelos, amenaza con sanciones a aquellos pa√≠ses que no se al√≠neen con la pol√≠tica estadounidense y con valores democr√°ticos (incluye entre los no-democr√°ticos aquellos que imponen restricciones a la difusi√≥n de fake news online).\n\n\nChina: Artificialismo liderado por el Estado\nAunque el desarrollo de la IA en China se haya dado a partir de empresas privadas como las gigantes Tencent, Xiaomi, Alibaba, o startups como DeepSeek, el Estado ha jugado un papel fundamental en la creaci√≥n de un ecosistema de IA que busca liderar el mundo.\nSu pol√≠tica se basa en el control estricto de los modelos desarrollados en el pa√≠s, con la supervisi√≥n del gobierno. No obstante, a diferencia de la UE, que controla el riesgo de las aplicaciones, el gobierno chino deja el control a las empresas. La inversi√≥n es masiva desde el Estado y la iniciativa privada. En cierto sentido, funciona de modo an√°logo al modelo de industrializaci√≥n por sustituci√≥n de importaciones, donde el Estado busca crear un ecosistema de IA que le permita ser autosuficiente y no depender de la tecnolog√≠a extranjera. Tambi√©n favorece los modelos de c√≥digo abierto, que permiten a las empresas chinas desarrollar sus propios modelos y aplicaciones.\n\n\n\nUni√≥n Europea: Crisis de competitividad, soberan√≠a digital y transparencia\n\nLa Uni√≥n Europea habla en ingl√©s, pero sue√±a en alem√°n. Quiz√°s esta haya sido la l√≠nea subyacente del informe Draghi sobre la competitividad de la UE. El informe tiene un diagn√≥stico claro: la brecha de competitividad entre la UE y Estados Unidos y China se ha ampliado y se explica por un sector econ√≥mico muy claro: la econom√≠a digital. La apuesta por servicios y la ind√∫stria en la regi√≥n y la falta de un ecosistema digital europeo han llevado a la UE a una crisis de competitividad.\n\nLa IA no escapa a este marco econ√≥mico m√°s amplio. La pol√≠tica de IA de la UE se basa en la creaci√≥n de un marco regulatorio que busca garantizar la transparencia y la responsabilidad en el uso de la IA. La estrategia de la UE se centra en la creaci√≥n de un ecosistema de IA que sea seguro y confiable, con un enfoque en la protecci√≥n de los derechos fundamentales y la privacidad de los ciudadanos. La percepci√≥n, manifiesta por √örsula von der Leyen en su discurso en la cumbre de la IA en Paris de febrero de 2025, es que la IA todav√≠a es un sector en ciernes y que la UE tiene todav√≠a una oportunidad para liderar el desarrollo de la IA en el mundo.\n\nNo obstante, en las aplicaciones la regi√≥n sigue el paradigma de la pol√≠tica europea (liderada por la econom√≠a alemana) de favorecer aplicaciones industriales para la IA. Es lo que podemos observar en la declaraci√≥n de √örsula von der Leyden en la misma cumbre de la IA de Par√≠s. A eso se suma una apuesta a modelos de IA de c√≥digo abierto y la transparencia, algo que facilita la labor regulatoria de los gobiernos y el desarrollo de aplicaciones por parte de empresas nacionales. Tal visi√≥n est√° m√°s alineada con la pol√≠tica de China y de una percepci√≥n de la IA fundacional no como una mercanc√≠a, sino como una infraestructura.\nAunque no observemos a√∫n una pol√≠tica clara de desarrollo de modelos fundacionales por parte de las instituciones europeas (estoy seguro que vendr√°n pronto), como bloque regional, la UE demuestra una estrategia clara de soberan√≠a digital y regulaci√≥n de la IA. No obstante, algunos gobiernos, como Francia y Espa√±a, buscan obtener una ‚Äúsoberan√≠a de IA‚Äù por cuenta propia, es decir, de forma aislada y sin coordinaci√≥n con otros gobiernos de la regi√≥n compitiendo entre ellos para lanzar sus modelos en ‚Äúfranc√©s‚Äù o ‚Äúespa√±ol y lenguas co-oficiales‚Äù. Para ello, han lanzado sus propios modelos de IA que tienen dos caracter√≠sticas centrales: una inversi√≥n claramente insuficiente y falta de competitividad (sin contar con la total ausencia de sentido de rid√≠culo). Representan m√°s bien estrategias de mercadeo pol√≠tico que pol√≠ticas s√≥lidas de desarrollo de la tecnolog√≠a.\nLucie, la IA gabacha, ha sido motivo de burla por las alucinaciones que ha producido. La tuvieron que sacar de circulaci√≥n y volver a meterla en los laboratorios de desarrollo despu√©s que dijo que una vaca pon√≠a huevos. Se trata de un lanzamiento muy fuera de lugar, especialmente cuando Francia posee el ecosistema de IA privado m√°s desarrollado de Europa, con modelos como Mistral. Eso revela a√∫n una falta de claridad en t√©rminos del rol de los gobiernos en el desarrollo de la IA.\nAlia es la IA nacional espa√±ola, desarrollada en Barcelona. Financiada inicialmente con ‚Äúincre√≠bles‚Äù 10 millones de euros -seg√∫n el ministro su deseo es que lea Cervantes2-, pero ha sido entrenada predominantemente con textos de bases de datos p√∫blicas internacionales con mayor√≠a de tokens en ingl√©s o lenguas germ√°nicas. S√≥lo 16% de los tokens son en espa√±ol, vamos. Y, adem√°s, ni lee a Cervantes ni a Borges3. Muchos de esos tokens en espa√±ol provienen del BOE, que est√° facilito de bajar en internet y ya tiene muchos metadatos incluidos. As√≠ que, si le preguntas c√≥mo se dice ‚Äúperro‚Äù en espa√±ol, te puede responder ‚Äúdoj‚Äù. O, si pides informaci√≥n sobre c√≥mo ir de Salamanca a Madrid, te puede decir que tienes que hacer una solicitud en tres v√≠as al Ministerio de Transportes y rematar con un magn√≠fico ‚Äú¬øQuieres que repasemos el formulario casilla a casilla?‚Äù.",
    "crumbs": [
      "1.2 - Geopol√≠tica y la IA"
    ]
  },
  {
    "objectID": "geopolitics.html#footnotes",
    "href": "geopolitics.html#footnotes",
    "title": "Geopol√≠tica y la IA generativa",
    "section": "Notas",
    "text": "Notas\n\n\nVer el Global AI Index.‚Ü©Ô∏é\nEste es el video del ministro de transformaci√≥n digital, √ìscar L√≥pez, haciendo declaraciones dignas de las alucinaciones de un chatGPT 0.1 Beta sin sonrojarse.‚Ü©Ô∏é\nLa obra de Borges no est√° en dominio p√∫blico, as√≠ que si el ministro quisiera que su modelito fuera entrenado ‚Äúleyendo‚Äù a Borges, tendr√≠a que guardar algo de dinero para comprar los derechos a Mar√≠a Kodama y dem√°s herederos.‚Ü©Ô∏é",
    "crumbs": [
      "1.2 - Geopol√≠tica y la IA"
    ]
  },
  {
    "objectID": "asistentes.html",
    "href": "asistentes.html",
    "title": "Assistentes Virtuales Herramientas de productividad y ense√±anza",
    "section": "",
    "text": "Un investigador le dice a su asistente virtual:‚Äî‚ÄúLIA, necesito que busques art√≠culos sobre la procrastinaci√≥n.‚ÄùDespu√©s de una pausa, responde, LIA: ‚Äî ‚ÄúEntendido. Lo a√±ado a mi lista de tareas‚Ä¶ para revisar m√°s tarde.‚Äù\nGemini 2.5 Pro",
    "crumbs": [
      "2 - Asistentes virtuales"
    ]
  },
  {
    "objectID": "asistentes.html#qu√©-es-ia-generativa-y-c√≥mo-nos-sirve",
    "href": "asistentes.html#qu√©-es-ia-generativa-y-c√≥mo-nos-sirve",
    "title": "Assistentes Virtuales ",
    "section": "¬øQu√© es IA generativa y c√≥mo nos sirve?",
    "text": "¬øQu√© es IA generativa y c√≥mo nos sirve?\nLa IA generativa es un tipo de inteligencia artificial que utiliza algoritmos para crear contenido nuevo, como texto, im√°genes, m√∫sica y m√°s. Funciona a partir de dos elementos centrales: modelos que son capaces de aprender a partir de patrones empleando ciertas arquitecturas y grandes cantidades de datos. Modelos como el chatGPT, Gemini, DALL-E (ahora integrado en chatGPT), Suno o Midjourney son ejemplos de IA generativa. Estos modelos son capaces de generar texto, im√°genes o m√∫sica a partir de un conjunto de datos de entrenamiento.\nLa popularizaci√≥n de tales modelos ocurre en 2022 con el lanzamiento de chatGPT 3 por OpenAI. Este modelo fue capaz de generar texto de forma coherente y relevante a partir de una pregunta o un tema dado. Desde entonces, la adopci√≥n ha sido r√°pida y creciente y, en el √°mbito educativo, se ha empezado a notar por la mejora en la calidad ling√º√≠stica de los textos generados por los estudiantes. De pronto, los textos sonaban m√°s fluidos, con mejor ortograf√≠a y gram√°tica, as√≠ como m√°s articulados. Por esa misma raz√≥n, los modelos de lenguaje han sido recibidos con cautela y preocupaci√≥n por parte de los educadores. Hoy, resulta dif√≠cil incluso para los mismos modelos de IA detectar qu√© textos han sido generados por ellas o por un humano. El problema est√° en que los falsos positivos son comunes: identifican escritos humanos como generados por IA.\nNo obstante, la aplicaci√≥n de los modelos de IA no quedaron solo en hacer trampas para aprobar una asignatura. Nuevas aplicaciones permiten a profesores e investigadores emplear la IA generativa para crear nuevos materiales para sus clases, automatizar tareas repetitivas, generar ideas para proyectos o incluso crear contenido multimedia. Tambi√©n podemos aprovechar la IA generativa como un ayudante de docencia. La creaci√≥n de tutores virtuales permiten la personalizaci√≥n del aprendizaje de los estudiantes, adaptando el contenido a sus necesidades y estilos.\nEn el √°mbito de la investigaci√≥n, podemos crear simulaciones, extraer datos de textos, o clasificar textos, entre muchas otras aplicaciones relacionadas a la s√≠ntesis de literatura, la correcci√≥n y traducci√≥n de textos acad√©micos. A√∫n tenemos mucho que aprender y desarrollar en t√©rminos de aplicaciones pr√°cticas de la IA generativa. Por esa misma raz√≥n, hace falta conocer c√≥mo funcionan para poder aprovecharlos.",
    "crumbs": [
      "2 - Asistentes virtuales"
    ]
  },
  {
    "objectID": "asistentes.html#chatgpt-y-sus-amigos",
    "href": "asistentes.html#chatgpt-y-sus-amigos",
    "title": "Assistentes Virtuales ",
    "section": "chatGPT y sus amigos",
    "text": "chatGPT y sus amigos\nAunque el chatGPT ha sido el modelo m√°s popularizado, √©l no est√° solito en el mundo. Existen muchos otros modelos alternativos que han sido desarrollados por diferentes empresas y organizaciones. El ecosistema de IA est√° dominado ahora mismo por una mezcla entre grandes corporaciones de informaci√≥n (Meta, Alibaba, Google, Microsoft) y start-ups que han podido ver su capital crecer exponencialmente en los √∫ltimos a√±os, con inversiones indirectas o colaboraciones empresariales con grandes tecnol√≥gicas (OpenAI, Mistral, DeepSeek, Perplexity).\nEsto se debe a la cantidad de capital necesario para llevar a cabo el entrenamiento y sostener el funcionamiento de los modelos. En t√©rminos econ√≥micos, se trata de un mercado de tipo oligopol√≠stico. Tal caracter√≠stica ser√° importante para lo que discutiremos en la pr√≥xima parte del curso, puesto que establece las condiciones fundamentales del juego pol√≠tico y estrat√©gico de empresas y pa√≠ses en el desarrollo de esa tecnolog√≠a.\nEn este apartado me centro en solamente introducir algunos de los modelos m√°s punteros en el campo de la IA generativa y, en particular, los modelos de lenguaje.\nAqu√≠ hay una lista de algunos de los modelos m√°s conocidos:\n\nGemini: Desarrollado por Google. Actualmente, la versi√≥n 2.5 Pro (con un acceso gratuito limitado a los usuarios de Google) es la m√°s actual. Se trata de un modelo muy capaz que est√° en la puntera de muchos benchmarks que eval√∫an la calidad de los modelos. Interpreta im√°genes, texto y es capaz de razonar1. Acceso aqu√≠.\nClaude: Desarrollado por Anthropic, Claude Sonnet 3.7 representa el modelo m√°s avanzado de la compa√±√≠a y est√° a la par con chatGPT y Gemini. Tambi√©n es capaz de interpretar im√°genes, textos y de razonamiento h√≠brido. Su diferencial (por ahora) se encuentra en la generaci√≥n e interpretaci√≥n de c√≥digo. Acceso aqu√≠.\nGrok: Desarrollado por X. AI. Se trata de un modelo se integra con la aplicaci√≥n de mensajer√≠a X (anteriormente Twitter) o se puede acceder directamente. Su versi√≥n Grok 3 permite la interpretaci√≥n y creaci√≥n de im√°genes, textos y razonamiento. Acceso aqu√≠.\nLlama: Desarrollado por Meta. Se trata de uno de los primeros modelos de c√≥digo abierto y libres para descarga existente en el mercado. Su √∫ltima versi√≥n Llama 4 no ha tenido mucho √©xito en los benchmarks, pero revela una apuesta s√≥lida de Meta por el desarrollo de un modelo de IA propio. Acceso aqu√≠.\nMistral: Desarrollado por la start-up francesa Mistral AI. Es el √∫nico modelo europeo ‚Äúcompetitivo‚Äù en el mercado. Aunque no sea un modelo razonador, puede generar e interpretar im√°genes, as√≠ como texto. Acceso aqu√≠.\nDeepSeek: Desarrollado por una start-up china de mismo nombre, este modelo ha sorprendido a todos en enero de 2025 por obtener un desempe√±o comparable a los grandes modelos a un coste mucho menor. Se trata de un modelo exclusivamente de generaci√≥n de texto, pero razonador y de c√≥digo abierto. Su lanzamiento ha cambiado las estrategias de muchas empresas en el sector y ha dinamizado el proceso de generaci√≥n de nuevas versiones. Acceso aqu√≠.\nQwen: Desarrollado por el grupo Alibaba. Se trata de un modelo de generaci√≥n de texto y razonador h√≠brido con un desempe√±o tambi√©n destacable. Acceso aqu√≠.",
    "crumbs": [
      "2 - Asistentes virtuales"
    ]
  },
  {
    "objectID": "asistentes.html#tipos-de-modelo",
    "href": "asistentes.html#tipos-de-modelo",
    "title": "Assistentes Virtuales ",
    "section": "Tipos de modelo",
    "text": "Tipos de modelo\n\n\n\nTipos de modelos de IA en la plataforma Hugging Face.",
    "crumbs": [
      "2 - Asistentes virtuales"
    ]
  },
  {
    "objectID": "asistentes.html#la-arquitectura-basada-en-transformers",
    "href": "asistentes.html#la-arquitectura-basada-en-transformers",
    "title": "Assistentes Virtuales ",
    "section": "La arquitectura basada en transformers",
    "text": "La arquitectura basada en transformers\n¬øC√≥mo decidimos cu√°l es el mejor modelo? ¬øQu√© modelo empleo si quiero que me resuma un libro entero? ¬øQu√© hago para que el texto generado sea m√°s creativo o, al contrario, m√°s fiel a un texto cient√≠fico o anal√≠tico? Para responder a estas preguntas, es importante entender c√≥mo funciona la arquitectura basada en transformers de los modelos de IA generativa actuales.\nLos modelos de IA generativa actuales emplean una arquitectura basada en redes neuronales y aprendizaje profundo. Tanto modelos de lenguaje, como el chatGPT, o de imagen y sonido, pueden emplean una arquitectura de tipo Transformers (El T de chatGPT viene de ah√≠). Estos modelos son capaces de aprender patrones complejos empleando un mecanismo de atenci√≥n (foco en atributos centrales) y generan los datos de forma secuencial o paralela (una palabra de cada vez).\nEl video abajo explica de forma visual y bastante accesible el funcionamiento de un modelo de IA generativa basado en la arquitectura de tipo transformer.\n\nNos introduce a conceptos que nos ser√°n √∫tiles durante todo el curso:\n\nembeddings - Se trata de representar palabras o frases en el formato de vectores (conjuntos de n√∫meros). Facilita b√∫squedas sem√°nticas y permite que el modelo entienda el significado de las palabras en un contexto determinado2.\ntokens - Representan unidades de texto que el modelo procesa y genera. Pueden ser palabras completas o partes de palabras.\npar√°metros - Corresponden a valores que el modelo ajusta durante el entrenamiento para aprender patrones en los datos. Una vez entrenados, los par√°metros son los pesos que el modelo utiliza para hacer predicciones.\ncapas - Son las partes del modelo que procesan la informaci√≥n y aprenden patrones a partir de un conjunto de par√°metros que se ajustan durante el entrenamiento para mejorar la precisi√≥n del modelo.\ntemperatura - Representa un par√°metro que controla la aleatoriedad de las respuestas generadas por el modelo, afectando la creatividad y diversidad de las salidas. Se trata de un ajuste fundamental para establecer el tono y nivel de creatividad de las respuestas generadas por el modelo. Una temperatura baja produce respuestas m√°s predecibles y coherentes, mientras que una temperatura alta genera respuestas m√°s variadas y creativas3.\nventana de contexto - Se refiere a la cantidad de texto que el modelo puede procesar y recordar al mismo tiempo. Un contexto m√°s largo permite al modelo generar respuestas m√°s coherentes y relevantes. La ventana de contexto define, por ejemplo, cu√°ntas preguntas y respuestas anteriores el modelo puede recordar y utilizar para generar nuevas respuestas en un chat4.",
    "crumbs": [
      "2 - Asistentes virtuales"
    ]
  },
  {
    "objectID": "asistentes.html#modelos-no-razonadores-razonadores-e-h√≠bridos",
    "href": "asistentes.html#modelos-no-razonadores-razonadores-e-h√≠bridos",
    "title": "Assistentes Virtuales ",
    "section": "Modelos no-razonadores, razonadores e h√≠bridos",
    "text": "Modelos no-razonadores, razonadores e h√≠bridos\nUno de los temas m√°s controvertidos en la adopci√≥n de modelos de lenguaje ha sido la cantidad de veces en las que produc√≠an respuestas incorrectas o incoherentes. En el jarg√≥n de la IA, a esto se le llama alucinaciones. Son el resultado de un modelo que intenta responder, pero no sabe c√≥mo o porque el proceso de respuesta requiere una serie de pasos intermedios que el modelo no puede realizar. Los modelos GPT tradicionales son considerados no-razonadores, porque simplemente intentan predecir la siguiente palabra en una secuencia de texto. No obstante, en algunos casos, algunas preguntas pueden conducir a respuestas incorrectas o incoherentes si el modelo no ha sido entrenado para contestarlas.\nPara evitar esos percances, se han desarrollado estrategias para que los modelos pudieran dar respuestas m√°s precisas a problemas complejos. Una de esas estrategias es la de razonamiento encadenado (o chain of thought)5. Esta estrategia consiste en dividir una tarea en pasos intermedios y hacer que el modelo piense en c√≥mo ser√≠a la manera de resolverlos uno a uno antes de generar la respuesta final. De esta forma, se pueden generar respuestas m√°s precisas y coherentes. Las empresas empezaron a entrenar a sus modelos en este tipo de razonamiento para producir mejores resultados.\n\n\n\nProceso de razonamiento de un modelo LLM.\n\n\nLos modelos razonadores son excelentes para tareas complejas. Sin embargo, tienen una gran desventaja: son costosos para ejecutar. Utilizarlos para preguntas sencillas o tareas simples puede ser ineficiente, pues generan muchas m√°s palabras de las necesarias. En pocas palabras, m√°s dinero, m√°s tiempo y m√°s energ√≠a. Por esa raz√≥n, m√°s recientemente (en 2025), OpenAI, Alibaba, Google, Anthropic y otras empresas han publicado modelos h√≠bridos que combinan la capacidad de razonamiento encadenado con la generaci√≥n de texto. Tales modelos deciden cu√°ndo es necesario hacer un razonamiento encadenado y cu√°ndo no. Esto permite que el modelo sea m√°s eficiente y efectivo en la generaci√≥n de texto, al tiempo que reduce el costo y el tiempo de ejecuci√≥n.",
    "crumbs": [
      "2 - Asistentes virtuales"
    ]
  },
  {
    "objectID": "asistentes.html#llm-slm-par√°metros-y-cuantizaci√≥n",
    "href": "asistentes.html#llm-slm-par√°metros-y-cuantizaci√≥n",
    "title": "Assistentes Virtuales ",
    "section": "LLM, SLM: Par√°metros y Cuantizaci√≥n",
    "text": "LLM, SLM: Par√°metros y Cuantizaci√≥n\nCuando utilizamos un chat en la web para consultar el chatGPT, estamos enviando las preguntas a un servidor en alg√∫n lugar del mundo. El servidor recibe la pregunta, la procesa, genera una respuesta y nos env√≠a de vuelta. Este proceso se da, porque los grandes modelos de lenguaje (LLM) requieren una gran cantidad de recursos computacionales. Un ordenador personal, y menos un tel√©fono m√≥vil, no tiene la capacidad de procesamiento necesaria para ejecutar estos modelos.\nPor un lado, tales caracter√≠sticas implican una grande centralizaci√≥n y, por ende, control de los datos que se procesan y de las posibles aplicaciones derivadas de un modelo. Por otro, nos enfrentamos al problema de emplear una bomba at√≥mica para intentar matar a una mosca, es decir, que los LLM son demasiado grandes y complejos para tareas simples.\nPara lidiar con problemas como p√©rdida de privacidad de datos, libertad para el desarrollo de aplicaciones para fines concretos y la reducci√≥n de costes de procesamiento, se han desarrollado modelos m√°s peque√±os y eficientes, conocidos como SLM (Small Language Models). Estos modelos son m√°s r√°pidos y eficientes, pero pueden no ser tan precisos o vers√°tiles como los LLM. Los SLM son ideales para tareas simples o espec√≠ficas, donde la velocidad y la eficiencia son m√°s importantes que la precisi√≥n. Algunos de ellos se pueden ejecutar en ordenadores personales (como lo haremos en este curso) o incluso en tel√©fonos m√≥viles.\n¬øCu√°l es la diferencia entre un LLM y un SLM? Son b√°sicamente dos: el n√∫mero de par√°metros que emplean en la producci√≥n de texto y la cuantizaci√≥n, es decir, la precisi√≥n en los pesos de los par√°metros. Los modelos m√°s grandes de LLM contienen centenares de miles de millones de par√°metros o incluso billones. Los SLM son mucho m√°s peque√±os, con modelos de 1B, 3B, 7B, 32B, 70B (mil millones). Menos par√°metros representan menos recursos computacionales, pero tambi√©n menor calidad.\nLa cuantizaci√≥n se refiere al n√∫mero de d√≠gitos que cada peso (par√°metro) del modelo utiliza para la generaci√≥n de textos. Los LLM emplean una precisi√≥n de 32 bits, mientras que los SLM pueden emplear una precisi√≥n de 8 (Q8) o incluso 4 bits (Q4). Esto significa que los SLM requieren mucho menos memoria y capacidad de procesamiento (y, por lo tanto, son m√°s r√°pidos) que los m√°s grandes. Sin embargo, esto viene a coste de la precisi√≥n6.",
    "crumbs": [
      "2 - Asistentes virtuales"
    ]
  },
  {
    "objectID": "asistentes.html#modelos-de-negocio-y-formas-de-acceso",
    "href": "asistentes.html#modelos-de-negocio-y-formas-de-acceso",
    "title": "Assistentes Virtuales ",
    "section": "Modelos de negocio y formas de acceso",
    "text": "Modelos de negocio y formas de acceso\nFinalmente, antes de que pasemos al pr√≥ximo tema, debemos considerar c√≥mo las empresas han decidido disponibilizar sus modelos al p√∫blico. Como veremos en la pr√≥xima parte de la sesi√≥n, el tipo de licencia ser√° un elemento importante en la geopol√≠tica de la IA y en la competencia entre empresas. En particular, creo que es importante entender primero el tipo de licencia, es decir, qui√©n es el propietario y qu√© permite hacer con el modelo. En segundo lugar, tenemos que conocer los diferentes m√©todos por los cu√°les podemos acceder a los modelos.\nExisten dos tipos fundamentales de licencia. Los modelos propietarios son aquellos que pertenecen a una empresa que mantiene en secreto las informaciones sobre el entrenamiento y los datos que han empleado para su desarrollo. Tambi√©n suelen bastante restrictivos en cuanto a qu√© se puede hacer con los modelos. Empresas como OpenAI, Anthropic o Google, por ejemplo, suelen tener modelos que proh√≠ben ciertas pr√°cticas, como el uso comercial sin pagar por ello una tasa especial. Otras empresas tampoco pueden modificar el modelo para adaptar a sus necesidades o para desarrollar aplicaciones espec√≠ficas. La velocidad de innovaci√≥n aqu√≠ depende exclusivamente de los equipos de investigaci√≥n de las empresas y de su capacidad de atraer talento.\nPor otro lado, los modelos de c√≥digo abierto son aquellos que han sido desarrollados por una comunidad de investigadores que han decidido compartir el c√≥digo o los datos de entrenamiento. Estos modelos suelen ser m√°s flexibles y permiten a los usuarios personalizarlos y adaptarlos a sus necesidades. Modelos abiertos permiten que un n√∫mero mayor de desarrolladores experimenten con ellos y desarrollen mejoras o aplicaciones espec√≠ficas. Este es el caso de modelos como Llama, DeepSeek, Qwen, Gemma 3 de Google, o Phi de Microsoft.\nAhora, ¬øc√≥mo podemos acceder a los modelos? Existen tres formas principales de acceso. La primera es por medio de una interfaz de tipo chat en el navegador o en una aplicaci√≥n m√≥vil. Este es el caso de chatGPT, por ejemplo, que puedes tanto abrir en un navegador como instalar su app en el tel√©fono. Su gran ventaja es la sencillez en el uso. Cualquiera sin conocimientos t√©cnicos puede usarla sin grandes dificultades. Tal falicidad de uso tambi√©n explica la enorme popularidad de chatGPT y similares. La financiaci√≥n o el pago por el servicio ocurre por una subscripci√≥n mensual o anual a diferentes niveles de servicio disponibles (b√°sico y pro, por ejemplo). Se tratan de modelos llamandos, freemium, donde el acceso b√°sico es gratuito, pero el acceso a funciones avanzadas o a un mayor n√∫mero de peticiones es de pago.\nEste modo de acceso tiene algunos inconvenientes importantes cuando queremos tratar una cantidad muy grande de informaciones. Por ejemplo, imaginemos que buscamos emplear los modelos para generar comentarios de cinco tareas distintas de los 80 estudiantes matriculados en una misma asignatura, es decir, un total de 400 documentos. Con un modelo de chat, tendr√≠amos que ir copiando y pegando cada uno de los textos en el chat, esperar que nos genere los comentarios y, luego, volver a copiar los resultados y guardarlos en archivos. Finalmente, tendr√≠amos que enviar dichos comentarios uno a uno a los estudiantes por correo o subirlo a la plataforma.\nNo cremo que repetir una misma tarea 400 veces sea una buena idea. Para esos casos, existen APIs (Application Programming Interfaces), que son interfaces de programaci√≥n que permiten que utilizemos lenguajes de programaci√≥n como el R o el Python para interactuar con el modelo de lenguaje. Las APIs permiten leer los archivos, enviarlos al modelo, recibir las respuestas, guardarlas en archivos y comunicar por correo electr√≥nico los comentarios de modo autom√°tico a cada uno de los estudiantes de forma personalizada.\nUna API funciona de una forma bastante distinta a un chat. En primer lugar, el usuario o investigador tiene que registrarse en la p√°gina web de la empresa y conseguir un token de acceso. Este token es un c√≥digo √∫nico que identifica al usuario y le permite acceder a la API. Se suele pagar por el uso. En el caso de los modelos de generaci√≥n de texto, se cobra por el n√∫mero de tokens que se env√≠an y reciben. Un token es una unidad de texto que puede ser tan corta como un solo car√°cter o tan larga como una palabra. Por ejemplo, la palabra ‚Äúgato‚Äù se considera un token, pero tambi√©n lo son los caracteres ‚Äúg‚Äù, ‚Äúa‚Äù, ‚Äút‚Äù y ‚Äúo‚Äù. En general, un token equivale a 4 caracteres en ingl√©s o 3 en espa√±ol. Una vez que tenga el token, se puede enviar una solicitud de informaci√≥n al servidor que contiene el modelo de lenguaje, que lo procesar√° y enviar√° una respuesta en un formato estructurado.\nEl c√≥digo abajo, por ejemplo, pregunta qu√© es un apag√≥n al modelo Gemini 2.5 Pro de Google7:\n\nC√≥digo\nlibrary(ellmer)\n\nchat &lt;- chat_gemini(\n            base_url = \"https://generativelanguage.googleapis.com/v1beta/\",\n            model = \"gemini-2.5-pro-exp-03-25\", \n            echo = \"none\")\n\nrespuesta &lt;- chat$chat(\"¬øQu√© es un apag√≥n?\")\n\ncat(respuesta)\n\nFin de los resultados\nC√≥mo hab√©is visto, el modelo me devuelve un texto ya formatado que se integra perfectamente al texto de R Markdown. Si quisiera, podr√≠a haber pedido que el modelo generara una tabla o un conjunto de valores separados por comas o incluso un gr√°fico o un esquema (para modelos que generan im√°genes) y, a continuaci√≥n, tratar dicha informaci√≥n y analizarla empleando estad√≠sticas o nuevas visualizaciones.\nNo obstante, el uso de APIs contiene algunos inconvenientes. El primero se encuentra en la privacidad. Al enviar los datos a un servidor de una empresa externa, puedo estar exponiendo informaci√≥n sensible o confidencial. Segundo, el uso de APIs puede ser costoso, particularmente si el volumen de informaci√≥n es muy grande o el n√∫mero de tokens a ser procesado muy alto. Imag√≠nense pedir que un modelo genere un resumen de todos los diarios de sesiones de los √∫ltimos 20 a√±os de 14 pa√≠ses de Am√©rica Latina. Para que tengamos una noci√≥n, una legislatura en un pa√≠s como Espa√±a puede generar diarios de sesiones que reunen m√°s de 20 mil p√°ginas y 30 millones de palabras (algo m√°s que 60 millones de tokens) en una sola legislatura. El procesamiento de tal informaci√≥n puede costar bastante.\nUna soluci√≥n a estos problemas es el uso de modelos locales. Como hemos visto, algunas empresas ofrecen modelos de c√≥digo abierto que se pueden descargar y ejecutar en servidores privados en la nube o en ordenadores locales. Aplicaciones como LM Studio o servidores locales como Ollama permiten acceder a modelos de c√≥digo abierto de forma local, sin problemas de coste o privacidad8.\nEl c√≥digo abajo repite la misma pregunta que antes, pero ahora usando el modelo de c√≥digo abierto Gemma 3 con 4B par√°metros de Google. En este caso, el modelo se encuentra instalado en mi ordenador y no tengo que pagar por su uso. El √∫nico coste es el de la electricidad y el del ordenador que lo ejecuta. Obviamente, la ejecuci√≥n ser√° m√°s lenta que en un servidor m√°s potente, pero me da mucha libertad y flexibilidad en el uso:\n\nC√≥digo\nlibrary(rollama)\n\nrespuesta &lt;- query(\"¬øQu√© es un apag√≥n?\",\n                 model = \"gemma3:4b\",\n                 output = \"text\",\n                 screen = FALSE)\n\ncat(respuesta)\n\nFin de los resultados\nComo se puede observar, el modelo peque√±o de Google (con s√≥lo 4 mil millones de par√°metros) es capaz de generar un texto bastante similar al de Gemini 2.5 Pro (que tiene m√°s de 100 mil millones de par√°metros). La diferencia entre ambos modelos es que el primero es un modelo local y el segundo es un modelo remoto (en la nube). Obviamente, esta ha sido una consulta sencilla. El rendimiento no ser√≠a el mismo si se trataran de problemas m√°s complejos. De todos modos, en muchas aplicaciones, no necesitamos los modelos m√°s grandes y complejos, sino versiones m√°s r√°pidas y peque√±as que reduzcan costes, tengan flexibilidad para permitir experimentar y no expongan datos sensibles a empresas externas.",
    "crumbs": [
      "2 - Asistentes virtuales"
    ]
  },
  {
    "objectID": "asistentes.html#footnotes",
    "href": "asistentes.html#footnotes",
    "title": "Assistentes Virtuales Herramientas de productividad y ense√±anza",
    "section": "Notas",
    "text": "Notas\n\n\nPuedes encontrar el video completo del curso (aprox. 1:30h) en el siguiente enlace.‚Ü©Ô∏é",
    "crumbs": [
      "2 - Asistentes virtuales"
    ]
  },
  {
    "objectID": "asistentes.html#necesito-ayuda",
    "href": "asistentes.html#necesito-ayuda",
    "title": "Assistentes Virtuales ",
    "section": "¬°Necesito ayuda!",
    "text": "¬°Necesito ayuda!\naaas",
    "crumbs": [
      "2 - Asistentes virtuales"
    ]
  },
  {
    "objectID": "asistentes.html#prompt-engineering",
    "href": "asistentes.html#prompt-engineering",
    "title": "Assistentes Virtuales Herramientas de productividad y ense√±anza",
    "section": "Prompt Engineering",
    "text": "Prompt Engineering\nQue nadie se asuste por el nombre rimbombante. Prompt engineering no es magia ni un saber t√©cnico altamente complejo. Tampoco te animes demasiado. No te convertir√°s en un ingeniero al aprender a escribir prompts. De forma sencilla, podemos definirlo como una t√©cnica (o ‚Äúarte‚Äù) de crear instrucciones en lenguaje natural para que un modelo de IA generativo lleve a cabo tareas espec√≠ficas. Aunque existan algunas heur√≠sticas que introduciremos aqu√≠ que facilitan el trabajo, una persona con capacidades cr√≠ticas y l√≥gicas puede aprender a crear nuevas formas de interactuar con los modelos a partir de sus necesidades.\n¬øEsto significa que no vale nada lo que aprendemos aqu√≠? No, paremos el carro. Las ‚Äúf√≥rmulas‚Äù que examinaremos en esta clase son √∫tiles para empezar a trabajar con los modelos de IA generativa. Sin embargo, no son la √∫nica forma de interactuar con ellos. De hecho, la mayor√≠a de los modelos de IA generativa son capaces de aprender a partir de ejemplos y de la interacci√≥n con el usuario. Por ello, es importante que cada uno refire esas herramientas y las adapte al su repertorio ling√º√≠stico propio.\n¬øQu√© ganamos? En primer lugar, con un prompt podemos lograr hacer cosas que antes solamente estaba al alcance de programadores. Por ejemplo, podemos pedirle al modelo que extraiga informaci√≥n de un texto y la formatee en una tabla.\nCopia y pega el siguiente texto en cualquier chat de IA y observa c√≥mo responde:\n\nAct√∫a como un experto inform√°ticoPersona. Le voy a suministrar un texto sobre diferentes ciudades. Me interesan tres datos concretos: el nombre de la ciudad, la poblaci√≥n y la temperatura media en veranoContexto. Extrae esos tres datos del texto y devu√©lvemelos en una tabla con tres columnas: ‚ÄúCiudad‚Äù, ‚ÄúPoblaci√≥n‚Äù y ‚ÄúTemperatura media en verano‚Äù. Aprovecha y ordena los valores por orden alfab√©tica de nombre de la ciudad y representa la poblaci√≥n como miles de habitantesTarea. Elije el formato de salida que posibilite la mejor integraci√≥n y lectura por parte de programas estad√≠sticos o lenguajes de programaci√≥nSalida. El texto es el siguiente: ‚ÄúMadrid, la capital de la comunidad aut√≥noma con el mismo nombre, es, seg√∫n la mayor√≠a de sus 3,2 millones habitantes, una de las ciudades m√°s hermosas y brillantes del mundo. Aunque su clima resulte fr√≠o en invierno, sus veranos son c√°lidos, con temperaturas que suelen alcanzar los 30 grados cent√≠grados. Barcelona, la capital de Catalu√±a, es una ciudad costera con una poblaci√≥n de 1,6 millones de habitantes. Considerada como un centro cultural global, como Madrid, su clima es mediterr√°neo, con inviernos suaves y veranos c√°lidos, donde las temperaturas suelen estar en los 35 grados cent√≠grados. Valencia, situada en la costa este de Espa√±a, tiene una poblaci√≥n de 800 mil habitantes y un clima mediterr√°neo similar al de Barcelona, con temperaturas que rondan los 30 grados cent√≠grados en verano.\n\n\n\n\n\nCiudad\nPoblaci√≥n (miles)\nTemperatura mediaen verano (¬∞C)\n\n\n\n\nBarcelona\n1600\n35\n\n\nMadrid\n3200\n30\n\n\nValencia\n800\n30\n\n\n\n\nVemos c√≥mo el modelo genera un archivo de tipo CSV (Comma Separated Values) que puede ser le√≠do por programas estad√≠sticos como R o Python. En este caso, el modelo ha sido capaz de extraer informaci√≥n de un texto y devolverla en un formato estructurado. Esto es algo que antes solo pod√≠an hacer programadores con conocimientos avanzados de lenguajes de programaci√≥n.\nEn gran medida, lo que aprenderemos aqu√≠ es justamente a ‚Äúprogramar‚Äù, pero en lugar de aprender Python, R o C++, adaptaremos la l√≥gica del pensamiento computacional al lenguaje natural (nuestro espa√±ol). De forma muy resumida, programar consiste en dividir tareas complejas em subprocesos m√°s sencillos, encontrar patrones y estructuras que se repiten, abstraer, generalizar y desarrollar ‚Äúrecetas‚Äù (algoritmos) para resolver el problema paso a paso.\nEn el ejemplo arriba defino una persona: experto inform√°tico. Marco un objetivo: extraer una tabla con el nombre de la ciudad, la poblaci√≥n y la temperatura media en verano. Le digo al modelo el formato de entrada: un texto. Indico la informaci√≥n relevante: nombre de la ciudad, poblaci√≥n y temperatura. Tambi√©n establezco un conjunto de tareas: (a) extrae los datos; (b) devu√©lvemelos en una tabla (estructura de la salida); (c) ordena los valores por orden alfab√©tica de nombre de la ciudad; (d) representa la poblaci√≥n como n√∫meros equivalentes a miles de habitantes; y (e) pido que decida sobre el formato m√°s compatible para la salida. Finalmente, le suministro el texto que debe analizar.\nAqu√≠ tenemos el ejemplo de un texto, pero podr√≠a ser un listado de 1.000 tweets, intervenciones parlamentarias, cap√≠tulos de un libro, poemas, discursos, art√≠culos de prensa o cualquier otro tipo de texto. El modelo es capaz de extraer informaci√≥n relevante y devolverla en un formato estructurado. Adem√°s, en lugar de pedir que el modelo extrajera datos, podr√≠amos pedirle que clasificara textos de acuerdo con diferentes temas, sentimientos o que generara res√∫menes autom√°ticos de textos largos. Podr√≠amos suministrarles datos demogr√°ficos y solicitar que contestara a una encuesta o que corrigiera un ejercicio de los estudiantes.",
    "crumbs": [
      "2 - Asistentes virtuales"
    ]
  },
  {
    "objectID": "asistentes.html#help",
    "href": "asistentes.html#help",
    "title": "Assistentes Virtuales Herramientas de productividad y ense√±anza",
    "section": "Help!",
    "text": "Help!\nEstamos acostumbrados a pedir cosas a los modelos de inteligencia artifical. Lo hacemos de forma intuitiva, interativa y exploratoria. Empezamos muchas veces con una pregunta general y, poco a poco, refinamos nuestra consulta, ofrecemos datos contextuales o ejemplos para que el modelo finalmente nos genere un resultado que consideremos satisfactorio. En resumen, no tenemos siempre claro cuando empezamos a hablar con un chat de IA qu√© es lo que queremos, ni en qu√© formato el modelo nos debe responder. La situaci√≥n se complica cuando las tareas que la IA debe llevar a cabo son complejas y dependen de un conjunto de etapas intermediarias que, a su vez, requieren que se lleven a cabo elecciones o decisiones.\n¬øPor qu√© empezamos por aqu√≠? ¬øPor qu√© hablamos de c√≥mo charlamos con la IA? La respuesta es sencilla. La creaci√≥n de asistentes virtuales viene de la capacidad que tenemos de dar instrucciones a un modelo de IA generativo para que lleve a cabo un conjunto de tareas espec√≠ficas. Un asistente virtual que ayuda a los estudiantes a aprender tiene la tarea concreta de ayudar a los alumnos en tareas concretas de una asignatura. Un revisor virtual que ayuda a evaluar la calidad de una propuesta de investigaci√≥n cumple funciones distintas. Por ello, debe recibir instrucciones espec√≠ficas para esta finalidad.\nEn esta sesi√≥n del curso aprenderemos c√≥mo definir esas instrucciones que hacen que modelos gen√©ricos, que sirve para todo, se comporten como expertos en funciones concretas. De un lado, se trata de restringir su escopo y, de otro, de obtener mayor profundidad en su procesamiento. Para ello, tenemos que primero a crear prompts o conjuntos de instrucciones estructuradas.",
    "crumbs": [
      "2 - Asistentes virtuales"
    ]
  },
  {
    "objectID": "asistentes.html#pasos-a-seguir",
    "href": "asistentes.html#pasos-a-seguir",
    "title": "Assistentes Virtuales ",
    "section": "Pasos a seguir",
    "text": "Pasos a seguir\nEl siguiente video es un resumen del curso de prompt engineering de Google2. Explica paso a paso todo lo que vamos a ver a continuaci√≥n. Vale la pena verlo completo durante el intervalo entre las clases para consolidar lo que hemos aprendido.\n\nImagina que los modelos de IA como el chatGPT son como un ni√±o peque√±o que necesita instrucciones claras para hacer algo. Cuanto m√°s preciso y claro seas, mejor ser√° el resultado, especialmente cuando se trata de tareas complejas o espec√≠ficas. La t√©cnica de prompting consiste en un conjunto de estrategias empleadas para dar instrucciones a una IA generativa. Su objetivo consiste en guiar a la IA para que pueda llevar a cabo tareas especializadas como analizar datos o escribir textos para p√∫blicos concretos. Durante el curso, emplearemos algunos ejemplos de prompting que te ayudar√°n a realizar tareas de an√°lisis sencillas, como extraer informaci√≥n de textos o generar res√∫menes autom√°ticos.\n\n1. Define el ‚Äúpersonaje‚Äù\nLa mejor manera de guiar la IA consiste en definir una ‚Äúpersona‚Äù que quieres que el modelo asuma. Por ejemplo, si quieres que la IA te ayude a recolectar datos puedes decirle: ‚ÄúEres un investigador que necesita extraer datos de un conjunto de textos.‚Äù Eso ayudar√° al modelo a asumir una perspectiva especializada. No ser√° cualquier respuesta, sino que intentar√° simular la posici√≥n de un investigador.\n\n\n2. Describe la tarea (y los objetivos)\n¬øQu√© quieres que haga y c√≥mo? Parece trivial, ¬øverdad? Pero en muchos casos las personas no tienen una idea clara de qu√© quieren al preguntarle al modelo qu√© quieren. No resulta sorprendente que descubran a partir de un proceso dial√≥gico a partir de la interacci√≥n con el chat.\nUna vez que hayas definido el ‚Äúpersonaje‚Äù, debes describir la tarea que quieres que la IA realice. Por ejemplo, si quieres que la IA te ayude a recolectar datos, puedes decirle: ‚ÄúNecesito que extraigas el pa√≠s de origen, la edad y el sexo de las personas que aparecen en el texto.‚Äù\n\n\n3. Proporciona contexto y ejemplos.\nContexto - informaci√≥n adicional para permitir que el modelo se sit√∫e ante a qui√©nes se dirige y c√≥mo llevar a cabo la tarea.\nA qui√©nes se destina el resultado - si quieres que la IA te ayude a escribir un texto para un p√∫blico espec√≠fico, debes indicarle a qui√©n va dirigido. Por ejemplo, si quieres que la IA escriba un art√≠culo para un blog de ciencia, puedes decirle: ‚ÄúEscribe un art√≠culo sobre la procrastinaci√≥n dirigido a estudiantes universitarios.‚Äù Esto ayudar√° al modelo a adaptar su estilo y contenido al p√∫blico objetivo.\nCu√°l es la definici√≥n de √©xito - si quieres que la IA te ayude a escribir un texto, debes indicarle cu√°l es el resultado esperado. Por ejemplo, si quieres que la IA escriba un art√≠culo sobre la procrastinaci√≥n, puedes decirle: ‚ÄúEscribe un art√≠culo de 500 palabras sobre la procrastinaci√≥n.‚Äù Esto ayudar√° al modelo a entender qu√© tipo de texto est√°s buscando y a adaptarse a tus necesidades.\nInformaci√≥n adicional que quieres que el modelo procese. Por ejemplo, imag√≠nate que quieres que el modelo hable de democracia, pero que considere en particular la definici√≥n de 10 papers. Puedes leer los papers y decirle al modelo: ‚ÄúAqu√≠ tienes 10 papers sobre democracia. Quiero que los consideres y emplees su contenido para formular una definici√≥n general y v√°lida de democracia que sea compatible con los 10 textos.‚Äù Esto ayudar√° al modelo a entender el contexto y a adaptar su respuesta a tus necesidades.\nEjemplos - los ejemplos representan un recurso muy √∫til a la hora de ense√±ar los modelos de IA exactamente lo que queremos de ellos. Esta estrategia funciona muy bien en tareas en las que podemos proporcionar ejemplos claros y directos, como en tareas de clasificaci√≥n o extracci√≥n de datos. Por ejemplo, si quieres que la IA te ayude a recolectar datos, puedes proporcionarle un texto de ejemplo y decirle: ‚ÄúAqu√≠ tienes un texto de ejemplo.‚ÄùEl brasile√±o Rodrigo, de 47 a√±os, es profesor de ciencia pol√≠tica en la Universidad de Salamanca. La madrile√±a Pilar afincada en Barcelona, de 54 a√±os, es economista en el BBVA. Devu√©lveme: Rodrigo;Brasil;47;Polit√≥logo;Universidad de Salamanca\\nPilar;Espa√±a;54;Economista;BBVA‚Äù\n\n\n4. Define el formato de salida\nSi quieres que te devuelva los resultados en un formato espec√≠fico, debes definir c√≥mo quieres que el modelo te entregue los datos. Por ejemplo, puedes decirle: ‚ÄúDevu√©lveme los datos en un formato csv, separado por ; y con los nombres de las columnas son ‚Äònombre‚Äô ‚Äòpa√≠s‚Äô y ‚Äòedad‚Äô.‚Äù Tambi√©n puedes definir el tono en que el modelo devuelva los resultados. Puede ser un tono formal, informal, t√©cnico o con ejemplos dependiendo de tus necesidades.\n\n\n5. Establezca un tono\nEl tono es la forma en que se expresa el mensaje. Puede ser formal, informal, t√©cnico o con ejemplos dependiendo de tus necesidades. Por ejemplo, si quieres que la IA te ayude a escribir un art√≠culo para un blog de ciencia, puedes decirle: ‚ÄúEscribe un art√≠culo sobre la procrastinaci√≥n en un tono informal y divertido.‚Äù Esto ayudar√° al modelo a adaptar su estilo y contenido al tono que est√°s buscando.\n\n\n6. Incluye restricciones.\nSi hay alguna restricci√≥n que deba tener en cuenta, es importante que se la comuniques a la IA. Por ejemplo, si no quieres que la IA te devuelva datos de personas menores de edad o de ciertos pa√≠ses, debes dec√≠rselo.\n\n\n7. Eval√∫a los resultados.\nUna vez que la IA haya completado la tarea, es importante que eval√∫es los resultados. Si no son los esperados, puedes intentar reformular la tarea o proporcionar m√°s ejemplos para ayudar a la IA a entender mejor lo que quieres.\n\n\n8. Refina el prompt y vuelve a intentar.\nSi los primeros resultados obtenidos no corresponden a las necesidades, puedes siempre ajustar y refinar el prompt para obtener mejores resultados. Una vez obtenidos los resultados esperados, puedes automatizar el proceso para que el modelo haga el trabajo por ti.\nResulta importante ser muy claro. A veces, puede ser mejor definir puntos o √≠tenes que faciliten el entendimiento de la tarea. Utilizar frases cortas y con poca ambig√ºedad puede ser de gran ayuda. Organizar las instrucciones de forma secuencial y l√≥gica tambi√©n puede hacer toda la diferencia.",
    "crumbs": [
      "2 - Asistentes virtuales"
    ]
  },
  {
    "objectID": "asistentes.html#estrategias-de-prompting",
    "href": "asistentes.html#estrategias-de-prompting",
    "title": "Assistentes Virtuales Herramientas de productividad y ense√±anza",
    "section": "Estrategias de Prompting",
    "text": "Estrategias de Prompting\nPrompting b√°sico o zero-shot prompting\nEl prompting b√°sico consiste en hacer preguntas directas a la IA. Por ejemplo, ‚Äú¬øCu√°les son los principales problemas de la IA?‚Äù o ‚Äú¬øCu√°les son las aplicaciones de la IA en la educaci√≥n?‚Äù. Este tipo de prompting es √∫til para obtener respuestas r√°pidas y directas, pero puede no ser tan efectivo para tareas m√°s complejas.\nPrompting con ejemplos o few-shot prompting\nEl prompting con ejemplos consiste en proporcionar un ejemplo de la tarea que quieres que la IA realice. Por ejemplo, ‚ÄúAqu√≠ tienes un texto de ejemplo. ‚ÄòEl brasile√±o Rodrigo, de 47 a√±os, es profesor de ciencia pol√≠tica en la Universidad de Salamanca.‚Äô Devu√©lveme: Rodrigo;Brasil;47.‚Äù Este tipo de prompting es √∫til para tareas m√°s complejas, ya que ayuda a la IA a entender mejor lo que quieres.\nChain of Thought o prompting con razonamiento\nEl prompting con razonamiento consiste en proporcionar un razonamiento detr√°s de la tarea que quieres que la IA realice. Por ejemplo, ‚ÄúQuiero que me digas cu√°les son los principales problemas de la IA. Piensa en los problemas √©ticos, de privacidad y de sesgo.‚Äù Este tipo de prompting es √∫til para tareas m√°s complejas, ya que ayuda a la IA a entender mejor lo que quieres.\nTree of Thought o prompting con razonamiento estructurado\n\n\n\nEstrategias de prompting\n\n\n\n\n\nPoniendo todas las piezas juntas.",
    "crumbs": [
      "2 - Asistentes virtuales"
    ]
  },
  {
    "objectID": "asistentes.html#asistente-docente-virtual",
    "href": "asistentes.html#asistente-docente-virtual",
    "title": "Assistentes Virtuales Herramientas de productividad y ense√±anza",
    "section": "Asistente docente virtual",
    "text": "Asistente docente virtual\nAsistente de docencia virtual.",
    "crumbs": [
      "2 - Asistentes virtuales"
    ]
  },
  {
    "objectID": "asistentes.html#tutor-de-tfg",
    "href": "asistentes.html#tutor-de-tfg",
    "title": "Assistentes Virtuales Herramientas de productividad y ense√±anza",
    "section": "Tutor de TFG",
    "text": "Tutor de TFG\n\nAct√∫a como un profesor de ciencia pol√≠ticaPersona.\nSu tarea ser√° ayudar a los estudiantes a realizar sus trabajos de fin de grado.Tarea",
    "crumbs": [
      "2 - Asistentes virtuales"
    ]
  },
  {
    "objectID": "asistentes.html#elavuadores-de-proyectos",
    "href": "asistentes.html#elavuadores-de-proyectos",
    "title": "Assistentes Virtuales Herramientas de productividad y ense√±anza",
    "section": "Elavuadores de proyectos",
    "text": "Elavuadores de proyectos",
    "crumbs": [
      "2 - Asistentes virtuales"
    ]
  },
  {
    "objectID": "asistentes.html#c√≥mo-crear-un-prompt",
    "href": "asistentes.html#c√≥mo-crear-un-prompt",
    "title": "Assistentes Virtuales Herramientas de productividad y ense√±anza",
    "section": "¬øC√≥mo crear un prompt?",
    "text": "¬øC√≥mo crear un prompt?\nEl siguiente video es un resumen del curso de prompt engineering de Google1. Explica paso a paso todo lo que vamos a ver a continuaci√≥n. Vale la pena verlo completo durante el intervalo entre las clases para consolidar lo que hemos aprendido.\n\nEn esta parte de la sesi√≥n, aprenderemos algunos principios b√°sicos de prompt engineering. Se tratan de elementos fundamentales, como bloques de lego, que podemos combinar para generar instrucciones m√°s complejas. Como piezas de lego, pueden o no ser empleadas en un prompt. Su uso depender√° de la complejidad y el tipo de tarea que se desea ejecutar.\nComo he mencionado antes, el prompt engineering consiste en un conjunto de estrategias empleadas para dar instrucciones a una IA generativa. El prop√≥sito es que lleve a cabo tareas especializadas como analizar datos o escribir textos para p√∫blicos concretos. A continuaci√≥n presentar√© cada uno de dichos elementos y los testaremos en cualquier modelo que tengamos a disposici√≥n. No obstante, siempre eval√∫a tu prompt a partir de los resultados. Algunas veces pensamos que una estrategia funciona, pero al probarla, nos damos cuenta de que no es as√≠. Por lo tanto, es importante experimentar y ajustar los prompts seg√∫n los resultados obtenidos, que es lo que realmente importa.\n\n1. Define el ‚Äúpersonaje‚Äù\nUna de las formas m√°s originales de guiar la IA hacia una respuesta especializada consiste en definir una ‚Äúpersona‚Äù. Se trata de decir al modelo que asuma un rol o una identidad. Si queremos que el modelo corrija un texto, podemos decirle que act√∫e como un revisor ortogr√°fico profesional. Si queremos que haga un an√°lisis literario de novelas, podemos pedirle que act√∫e como un cr√≠tico literario con especializaci√≥n en narrativa. Se puede transformar en lo que queramos: analista de datos, historiador, economista, m√©dico, programador‚Ä¶\nAl definir una persona, el modelo ‚Äúemula‚Äù o imita el comportamiento de ese experto; asume su lenguaje, su forma de pensar y su conocimiento. Esto es especialmente √∫til cuando queremos que el modelo realice tareas que requieren un conocimiento especializado o un enfoque particular. En lugar de ofrecer respuestas generalistas, el modelo se adapta a la perspectiva del personaje que le hemos asignado.\nCopia y pega los siguientes textos (uno a la vez) en cualquier chat de IA y observa c√≥mo responden de forma distinta:\n\nPrompt sin persona:\nExplica el teorema de Pit√°goras.\nPrompt con persona:\nAct√∫a como un matem√°tico experto en geometr√≠aPersona. Explica el teorema de Pit√°goras.\n\n\nLo que podemos observar es que el modelo responde de forma diferente seg√∫n la persona que le hemos asignado. En el primer caso, la respuesta es m√°s general y menos t√©cnica, mientras que en el segundo caso, la respuesta es m√°s precisa y detallada, como se esperar√≠a de un matem√°tico experto en geometr√≠a.\n\n\n2. Describe la tarea (y los objetivos)\nEn esta segunda parte de un prompt, definimos qu√© queremos que el modelo haga y c√≥mo. Parece trivial, ¬øverdad? Pero, en muchos casos, las personas no tienen una idea clara de qu√© quieren al preguntarle al modelo. Instrucciones vagas o mal definidas reciben respuestas sub√≥ptima, para decirlo finamente. Por esa misma raz√≥n, no resulta sorprendente que el objetivo se revele a partir de un proceso dial√≥gico entre el usuario y el chat de IA.\nNos encontramos, por lo tanto, en el n√∫cleo del prompt. Un conjunto de instrucciones pueden prescindir de una persona o de ejemplos, pero no puede renunciar a definir de forma clara la tarea y los objetivos. Y aqu√≠ es donde puedes ganar mucho en t√©rminos de eficiencia y eficacia. Algunos factores a tener en cuenta:\n\nTipo de tarea - se trata de una tarea de lenguaje, como resumir, generar o clasificar un texto o de una tarea de an√°lisis, que requiere extraer y procesar informaci√≥n de un texto o de una tabla.\nComplejidad - consiste en establecer si la tarea representa algo sencillo, que no exije mucha elaboraci√≥n, o requiere dividir (divide et impera) el trabajo en un conjunto de etapas intermediarias que sirven de insumo para las siguientes. Por ejemplo, consultar informaci√≥n suele ser mucho m√°s sencillo que el an√°lisis de datos.\nClaridad - no se puede insistir m√°s en ese aspecto. Instrucciones ambiguas conducen a resultados indeseados o, al menos, sorprendentes.\nVocabulario - usa siempre vocabulario espec√≠fico o especializado. Si quieres que el modelo act√∫e como un experto en un campo concreto, usa t√©rminos t√©cnicos y espec√≠ficos de ese campo. Si hablamos de representaci√≥n pol√≠tica, podemos mencionar magnitud de distrito, proporcionalidad, umbral electoral, etc. Si hablamos de literatura, podemos mencionar narrador, trama, personajes, etc. Si hablamos de datos, podemos mencionar variables, observaciones, etc. En resumen, usa el vocabulario adecuado para la tarea que est√°s realizando.\n\nEmpleemos un ejemplo cercano a nosotros: el an√°lisis de una tabla. En este caso, la tabla contiene informaci√≥n sobre el PIB per c√°pita y el porcentaje de democracias en diferentes regiones del mundo. La tarea consiste en analizar la tabla y extraer informaci√≥n relevante, as√≠ como evaluar la relaci√≥n entre las dos variables. Como vemos, corresponde a una tarea com√∫n de cualquier ejercicio de an√°lisis de datos. El ejemplo abajo incluso podr√≠a ser empleado en una clase introductoria de metodolog√≠a para ense√±ar a los estudiantes c√≥mo llevar a cabo un an√°lisis b√°sico de datos.\n\n\n\n\n\n\n\n\nRegi√≥n\nPIB per c√°pitapromedio (USD)\nDemocracias (%)\n\n\n\n\nEuropa Occidental\n45,000\n100%\n\n\nOcean√≠a\n35,000\n85%\n\n\nAm√©rica del Norte\n65,000\n67%\n\n\nEuropa del Este\n18,000\n60%\n\n\nAm√©rica Latina\n10,000\n60%\n\n\nSudeste Asi√°tico\n5,000\n45%\n\n\nAsia Oriental\n20,000\n40%\n\n\nAsia Meridional\n2,500\n35%\n\n\n√Åfrica Subsahariana\n1,800\n20%\n\n\nOriente Medio y Norte de √Åfrica\n7,000\n15%\n\n\n\n\n\nA continuaci√≥n te presento un conjunto de valores separados por comas:Contexto ‚ÄúRegi√≥n,PIB_per_c√°pita_USD,Porcentaje_DemocraciasContexto Am√©rica del Norte,65000,67Contexto Europa Occidental,45000,100Contexto Europa del Este,18000,60Contexto Am√©rica Latina,10000,60Contexto √Åfrica Subsahariana,1800,20Contexto MENA,7000,15Contexto Asia Oriental,20000,40Contexto Asia Meridional,2500,35Contexto Sudeste Asi√°tico,5000,45Contexto Ocean√≠a,35000,85‚ÄùContexto\nAhora, quiero que analices los datos de la siguiente manera:Tarea\n1. Describe los patrones observados en la tabla y enfoca la relaci√≥n entre las dos variables num√©ricas: PIB per c√°pita y porcentaje de democracias en cada regi√≥n.Tarea\n2. Comenta si existe alguna relaci√≥n entre el PIB per c√°pita y el porcentaje de democracias en cada regi√≥n. Adem√°s, de un an√°lisis descriptivo de la relaci√≥n, incluye t√©rminos como el coeficiente de correlaci√≥n. Calcula el coeficiente de correlaci√≥n de Pearson e inf√≥rmalo.Tarea\n3. A partir de los an√°lisis anteriores, realiza un an√°lisis sobre la relaci√≥n entre el PIB per c√°pita y el porcentaje de democracias en cada regi√≥n. ¬øQu√© conclusiones puedes extraer?Tarea\n\n\nC√≥mo podemos ver en los resultados generados, los modelos generan un an√°lisis descriptivo detallado de los datos. La extensi√≥n y profundidad del an√°lisis puede variar seg√∫n el modelo empleado (Gemini, Claude, GPT4, etc.). Pero lo que queda absolutamente claro es que podemos emular estrategias de an√°lisis de datos que adoptados en nuestros propios an√°lisis, automatiz√°ndolas por medio de los modelos de IA.\n\n\n3. Proporciona contexto y ejemplos.\nEl tercer eje de la estrategia de prompting es proporcionar contexto y ejemplos. Dentro del marco de la IA generativa, podemos entender el concepto de contexto de tres maneras principales. En una primera acepci√≥n, se trata de definir de modo claro a qui√©nes se destina el resultado. Por ejemplo, si quieres que la IA escriba un art√≠culo para un blog de pol√≠tica, puedes decirle: ‚ÄúEscribe un art√≠culo sobre la democracia dirigido a un p√∫blico general interesado en pol√≠tica, pero que no tiene formaci√≥n acad√©mica en el tema.‚Äù Esto ayudar√° al modelo a adaptar su estilo y contenido al p√∫blico objetivo.\nA continuaci√≥n creamos un prompt que pide a la IA que prepare una clase sobre El pr√≠ncipe de Maquiavelo para estudiantes de ciencia pol√≠tica de primer a√±o. Aqu√≠, tratamos de definir las caracter√≠sticas de los estudiantes con relaci√≥n a los elementos que consideramos fundamentales para entender la obra del autor florentino. Primero, empiezan el curso y est√°n poco familiarizados con los conceptos de la ciencia pol√≠tica. Segundo, no tienen una formaci√≥n previa de filosof√≠a pol√≠tica, as√≠ que el modelo debe ajustar el lenguaje a un p√∫blico en especializaci√≥n, pero no especializado. Tercero, no podemos suponer que conocen mucho sobre el Renacimiento, Florencia o la historia de las rep√∫blicas italianas. Por lo tanto, el modelo debe proporcionar un contexto hist√≥rico y cultural para ayudar a los estudiantes a entender la obra.\n\nPrepara una clase sobre la obra ‚ÄúEl Pr√≠ncipe‚Äù de MaquiaveloTarea.\nEl p√∫blico est√° compuesto por estudiantes con las siguientes caracter√≠sticas:Contexto\n1. de primer a√±o del grado de ciencia pol√≠tica;Contexto\n2. no tienen formaci√≥n previa en filosof√≠a pol√≠tica;Contexto\n3. no podemos suponer que conocen mucho sobre el Renacimiento, Florencia o la historia de las rep√∫blicas italianas;Contexto\nPor esa raz√≥n, organiza la clase para no solo hablar de la obra, sino tambi√©n de su contexto hist√≥rico y pol√≠ticoTarea.\n\n\nEn una segunda interpretaci√≥n, el contexto se refiere a qu√© consideras como √©xito o el resultado esperado. Por ejemplo, si quieres que la IA escriba un art√≠culo sobre la erosi√≥n democr√°tica, puedes decirle: ‚ÄúEscribe un art√≠culo de 500 palabras sobre la erosi√≥n democr√°tica.‚Äù Esto ayudar√° al modelo a entender qu√© tipo de texto est√°s buscando y a adaptarse a tus necesidades.\nEn el ejemplo abajo, pedimos que la IA genere un conjunto de datos simulados o ‚Äúsint√©ticos‚Äù que podr√≠amos emplear en simulaciones (tambi√©n usando la IA) de encuestas de opini√≥n. Le indicamos, adem√°s, que genere tres variables (sexo, edad y nivel educativo) y que cada una de ellas tenga un peso espec√≠fico.\n\nGenera un conjunto de datos con 1500 observaciones que corresponda a una muestra representativa. Tarea\nNecesito de tal informaci√≥n para la simulaci√≥n de encuestas de opini√≥n. El conjunto de datos debe tener las siguientes variables (y el peso de cada categor√≠a):Contexto\n1. Sexo (masculino 49%, femenino 51%)Contexto\n2. Edad (de 18 a 24: 10%, de 25 a 34: 20%, de 35 a 44: 20%, de 45 a 54: 20%, de 55 a 64: 15%, de 65 o m√°s: 15%)Contexto\n3. Nivel educativo (primaria: 10%, secundaria: 30%, bachillerato: 25%, formaci√≥n profesional: 15%, universidad: 20%)Contexto\nCrea la base de datos en un formato CSV.Formato\n\n\nInformaci√≥n adicional que quieres que el modelo procese. Por ejemplo, imag√≠nate que quieres que el modelo hable de democracia, pero que considere en particular la definici√≥n de 10 papers. Puedes leer los papers y decirle al modelo: ‚ÄúAqu√≠ tienes 10 papers sobre democracia. Quiero que los consideres y emplees su contenido para formular una definici√≥n general y v√°lida de democracia que sea compatible con los 10 textos.‚Äù Esto ayudar√° al modelo a entender el contexto y a adaptar su respuesta a tus necesidades.\n\nA continuaci√≥n te presento un conjunto de valores separados por comas:Contexto\n\n\nEjemplos - los ejemplos representan un recurso muy √∫til a la hora de ense√±ar los modelos de IA exactamente lo que queremos de ellos. Esta estrategia funciona muy bien en tareas en las que podemos proporcionar ejemplos claros y directos, como en tareas de clasificaci√≥n o extracci√≥n de datos. Por ejemplo, si quieres que la IA te ayude a recolectar datos, puedes proporcionarle un texto de ejemplo y decirle: ‚ÄúAqu√≠ tienes un texto de ejemplo.‚ÄùEl brasile√±o Rodrigo, de 47 a√±os, es profesor de ciencia pol√≠tica en la Universidad de Salamanca. La madrile√±a Pilar afincada en Barcelona, de 54 a√±os, es economista en el BBVA. Devu√©lveme: Rodrigo;Brasil;47;Polit√≥logo;Universidad de Salamanca\\nPilar;Espa√±a;54;Economista;BBVA‚Äù\n\n\n4. Define el formato de salida\nSi quieres que te devuelva los resultados en un formato espec√≠fico, debes definir c√≥mo quieres que el modelo te entregue los datos. Por ejemplo, puedes decirle: ‚ÄúDevu√©lveme los datos en un formato csv, separado por ; y con los nombres de las columnas son ‚Äònombre‚Äô ‚Äòpa√≠s‚Äô y ‚Äòedad‚Äô.‚Äù Tambi√©n puedes definir el tono en que el modelo devuelva los resultados. Puede ser un tono formal, informal, t√©cnico o con ejemplos dependiendo de tus necesidades.\n\n\n5. Establezca un tono\nEl tono es la forma en que se expresa el mensaje. Puede ser formal, informal, t√©cnico o con ejemplos dependiendo de tus necesidades. Por ejemplo, si quieres que la IA te ayude a escribir un art√≠culo para un blog de ciencia, puedes decirle: ‚ÄúEscribe un art√≠culo sobre la procrastinaci√≥n en un tono informal y divertido.‚Äù Esto ayudar√° al modelo a adaptar su estilo y contenido al tono que est√°s buscando.\n\n\n6. Incluye restricciones.\nSi hay alguna restricci√≥n que deba tener en cuenta, es importante que se la comuniques a la IA. Por ejemplo, si no quieres que la IA te devuelva datos de personas menores de edad o de ciertos pa√≠ses, debes dec√≠rselo.\n\n\n7. Eval√∫a los resultados.\nUna vez que la IA haya completado la tarea, es importante que eval√∫es los resultados. Si no son los esperados, puedes intentar reformular la tarea o proporcionar m√°s ejemplos para ayudar a la IA a entender mejor lo que quieres.\n\n\n8. Refina el prompt y vuelve a intentar.\nSi los primeros resultados obtenidos no corresponden a las necesidades, puedes siempre ajustar y refinar el prompt para obtener mejores resultados. Una vez obtenidos los resultados esperados, puedes automatizar el proceso para que el modelo haga el trabajo por ti.\nResulta importante ser muy claro. A veces, puede ser mejor definir puntos o √≠tenes que faciliten el entendimiento de la tarea. Utilizar frases cortas y con poca ambig√ºedad puede ser de gran ayuda. Organizar las instrucciones de forma secuencial y l√≥gica tambi√©n puede hacer toda la diferencia.",
    "crumbs": [
      "2 - Asistentes virtuales"
    ]
  },
  {
    "objectID": "asistentes.html#otros-asistentes-de-ia",
    "href": "asistentes.html#otros-asistentes-de-ia",
    "title": "Assistentes Virtuales Herramientas de productividad y ense√±anza",
    "section": "Otros asistentes de IA",
    "text": "Otros asistentes de IA\ndd\n\nNotebookLM\nddd\n\n\nObsidian + Ollama\nsddd",
    "crumbs": [
      "2 - Asistentes virtuales"
    ]
  }
]